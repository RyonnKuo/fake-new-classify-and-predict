{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2077866c",
   "metadata": {
    "id": "2077866c"
   },
   "source": [
    "# **1132_MIS581社群媒體分析_期末專案_第一組**\n",
    "- 指導教授：黃三益\n",
    "- 　　組員：郭展州N124020012、傅才容N124320030、莊筑雅N124320004、李明容N124320016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68389ee3",
   "metadata": {},
   "source": [
    "# **專案名稱：多層次特徵融合之假新聞偵測與主題分析系統**\n",
    "## **專案目標**\n",
    "1. 精準判斷新聞或推文之真偽\n",
    "2. 剖析假新聞常見主題與關鍵字\n",
    "3. 結合多模型協作(傳統 ML × BERT/SBERT × LLM)，驗證不同特徵組合與分類器效果，建立可擴充的偵測流程\n",
    "## **專案流程**\n",
    "1. 資料蒐集與前處理\n",
    "2. 各項特徵提取：NER特徵、情緒特徵、綜合特徵工程及分類模型評估\n",
    "3. 主題模型BERTopic\n",
    "4. LLM 多模型裁決\n",
    "5. 最終整合評估\n",
    "## **資料來源**\n",
    "1. fake-and-real-news-dataset (ISOT Fake News detection dataset) https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
    "2. Twitter Dataset (Referenced from CIC Truth Seeker Dataset 2023) https://www.kaggle.com/datasets/sudishbasnet/truthseekertwitterdataset2023/data?select=Truth_Seeker_Model_Dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950fcec1",
   "metadata": {
    "id": "950fcec1"
   },
   "source": [
    "# **專案執行**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ade977",
   "metadata": {},
   "source": [
    "## 一、套件安裝與引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kHUIVdFdFJao",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134968,
     "status": "ok",
     "timestamp": 1749735935449,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "kHUIVdFdFJao",
    "outputId": "deb6b7b0-f9dc-46cd-af8d-cd7666eb0045"
   },
   "outputs": [],
   "source": [
    "# 🔧 安裝核心資料處理與模型套件\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn tqdm nltk vaderSentiment empath tabulate\n",
    "# 🔎 安裝 BERT 相關（transformers, pipeline）\n",
    "!pip install transformers\n",
    "# 🤖 安裝命名實體辨識用預訓練模型\n",
    "!pip install torch\n",
    "# 🧠 安裝情緒分析微調模型\n",
    "!pip install sentence-transformers\n",
    "# 📊 安裝主題建模：BERTopic + HDBSCAN（支援 clustering）\n",
    "!pip install bertopic hdbscan\n",
    "# 🗂 字體設定用（如你加載了自訂字體）\n",
    "!pip install fonttools\n",
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6tH_lAhbB52g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1749735936684,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "6tH_lAhbB52g",
    "outputId": "3ae7508e-acfd-43ae-a181-896ef1253e17"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 加速\n",
    "\n",
    "import torch\n",
    "\n",
    "# GPU 加速\n",
    "print(\"=== PyTorch GPU 加速環境檢查 ===\")\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"PyTorch 編譯的 CUDA 版本: {torch.version.cuda}\")\n",
    "print(f\"是否支援 CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        current_gpu = torch.cuda.current_device()\n",
    "        device_name = torch.cuda.get_device_name(current_gpu)\n",
    "\n",
    "        print(f\"偵測到 {gpu_count} 個 GPU\")\n",
    "        print(f\"當前使用的 GPU：{device_name}\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        raise RuntimeError(\"CUDA 不可用，將使用 CPU\")\n",
    "except Exception as e:\n",
    "    print(f\"無法使用 GPU：{e}\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"pytorch可用的GPU為：{device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bf351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === NLP / 資料處理基礎 ===\n",
    "import os, re, ssl, json, concurrent.futures, warnings, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLTK ───────────────────────────────────────────────────────────\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.data.path.extend([\n",
    "    '/usr/nltk_data', '/usr/local/nltk_data', '/usr/share/nltk_data',\n",
    "    '/usr/local/share/nltk_data', '/root/nltk_data'\n",
    "])\n",
    "\n",
    "# === Scikit-learn 基礎工具 ===\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_validate)\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer, CountVectorizer)\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, f1_score,\n",
    "    accuracy_score, precision_score, recall_score, make_scorer)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 傳統分類器\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# === 進階 NLP / 向量化 ===\n",
    "from sentence_transformers import SentenceTransformer          # SBERT\n",
    "from transformers import (\n",
    "    pipeline, AutoTokenizer, AutoModelForTokenClassification)\n",
    "\n",
    "# === 主題模型 / 聚類 ===\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# === 視覺化 ===\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import fontManager\n",
    "fontManager.addfont('./public/TaipeiSansTCBeta-Regular.ttf')\n",
    "plt.rcParams['font.sans-serif'] = ['Taipei Sans TC Beta']\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# === VADER & Empath (情緒 / 詞典) ===\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "try:\n",
    "    from empath import Empath\n",
    "    empath_available = True\n",
    "    empath_lexicon = Empath()\n",
    "except ModuleNotFoundError:\n",
    "    empath_available = False\n",
    "    warnings.warn(\"Empath 尚未安裝，將略過相關特徵。\")\n",
    "\n",
    "# === 其他輔助 ===\n",
    "from tabulate import tabulate\n",
    "warnings.filterwarnings('ignore')  # 避免雜訊訊息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68d7c7",
   "metadata": {},
   "source": [
    "### 匯入fake-and-real-news-dataset真假新聞資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b54574",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1749735938072,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "59b54574",
    "outputId": "5392bcac-87d5-4327-b9fb-5b10e98dc092"
   },
   "outputs": [],
   "source": [
    "# 載入fake-and-real-news-dataset資料集\n",
    "fake_df = pd.read_csv('./raw_data/fake.csv')            \n",
    "true_df = pd.read_csv('./raw_data/true.csv')            \n",
    "\n",
    "# 合併 title 和 text 成新的 text 欄位\n",
    "fake_df['text'] = fake_df['title'].astype(str) + \" \" + fake_df['text'].astype(str)\n",
    "true_df['text'] = true_df['title'].astype(str) + \" \" + true_df['text'].astype(str)\n",
    "\n",
    "# 加上 label 欄位\n",
    "fake_df['label'] = 1\n",
    "true_df['label'] = 0\n",
    "\n",
    "# 取前 1000 筆\n",
    "# dataNum = 1000\n",
    "# news_data = pd.concat([fake_df.iloc[:dataNum], true_df.iloc[:dataNum]], ignore_index=True)\n",
    "# news_data = fake_df\n",
    "\n",
    "# 取一半(資料量過大)\n",
    "fake_half = fake_df.sample(frac=0.1, random_state=42)\n",
    "true_half = true_df.sample(frac=0.1, random_state=42)\n",
    "news_data = pd.concat([fake_half, true_half], ignore_index=True)\n",
    "\n",
    "# 移除空值並只保留 text 和 label 欄位\n",
    "news_data = news_data[news_data['text'].notna()].reset_index(drop=True)\n",
    "news_data = news_data[['text', 'label']]\n",
    "\n",
    "# 檢查各類別數量\n",
    "print(news_data['label'].value_counts())\n",
    "print(news_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8c468",
   "metadata": {
    "id": "18a8c468"
   },
   "source": [
    "### 匯入Twitter Dataset推特真假推文資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7806f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1749735938208,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "1c7806f2",
    "outputId": "ef86ba43-79ee-452b-e3c0-ed6fc9b7522e"
   },
   "outputs": [],
   "source": [
    "# 推特資料處理(為了嘗試解決 加入TF-IDF過擬合&embed過強 可能是因為文本特徵太明顯的問題)\n",
    "tweet_df = pd.read_csv(\n",
    "    './raw_data/Truth_Seeker_Model_Dataset_unindex.csv', encoding='ISO-8859-1')\n",
    "tweet_data = tweet_df[['BinaryNumTarget',\n",
    "                       'tweet', '5_label_majority_answer']].copy()\n",
    "\n",
    "# 清理\n",
    "tweet_data = tweet_data.dropna()\n",
    "tweet_data = tweet_data[~tweet_data['tweet'].str.contains('#REF!', na=False)]\n",
    "valid_labels = ['Agree', 'Mostly Agree']\n",
    "tweet_data = tweet_data[tweet_data['5_label_majority_answer'].isin(\n",
    "    valid_labels)]\n",
    "\n",
    "# 移除 5_label_majority_answer 欄位，並重新命名欄位\n",
    "tweet_data = tweet_data.rename(\n",
    "    columns={'BinaryNumTarget': 'label', 'tweet': 'text'})\n",
    "tweet_data = tweet_data[['text', 'label']]\n",
    "\n",
    "tweet_data_num = 50  # 取n筆\n",
    "# 取比例\n",
    "min_half = int(min(tweet_data['label'].value_counts()) / 10)\n",
    "# tweet_data = tweet_data.groupby('label').apply(\n",
    "#     lambda x: x.sample(n=min(len(x), min_half), random_state=42)\n",
    "# ).reset_index(drop=True)\n",
    "tweet_data = tweet_data.groupby('label').apply(\n",
    "    lambda x: x.sample(n=min_half, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(tweet_data['label'].value_counts())\n",
    "print(tweet_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ab861",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1749735938240,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "4c3ab861"
   },
   "outputs": [],
   "source": [
    "# 合併兩份不同來源資料集\n",
    "data = pd.concat([news_data, tweet_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b5ac9",
   "metadata": {
    "id": "3b7b5ac9"
   },
   "source": [
    "**需要做文本預處理嗎?**\n",
    "\n",
    "目的:\n",
    "- 建立分類器來預測真假新聞 -> (TF-IDF + 分類模型需要乾淨的資料，有幫助)\n",
    "- 分析NER 結果與語意分佈 -> (會破壞語意)\n",
    "- 建立主題模型來探索語意主題（BERTopic -> (會破壞語意)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e324aa",
   "metadata": {
    "executionInfo": {
     "elapsed": 1467,
     "status": "ok",
     "timestamp": 1749735939726,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "d5e324aa"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punct_pattern = re.compile(r\"[^a-z ]\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = punct_pattern.sub(\" \", text)\n",
    "    # 用 preserve_line=True 避開 punkt_tab\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(w)\n",
    "        for w in tokens\n",
    "        if w not in stop_words and len(w) > 1\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "data['tokens'] = data['text'].astype(str).apply(preprocess)\n",
    "data['clean_text'] = data['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ddd12",
   "metadata": {
    "id": "e68ddd12"
   },
   "source": [
    "## 二、各項特徵處理與分類器評估表現\n",
    "### NER特徵處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29def4a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328342,
     "status": "ok",
     "timestamp": 1749736268119,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "29def4a1",
    "outputId": "0c7820aa-6dfd-44e1-be4e-230ce207a5b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "from transformers import BertTokenizerFast, AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 載入模型與 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=0)\n",
    "\n",
    "# 建立 NER 結果列表\n",
    "ner_rows = []\n",
    "\n",
    "# 分切字串\n",
    "def split_text(text, chunk_size=512):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 針對每篇文章跑 NER（可用 tqdm 顯示進度條）\n",
    "for idx, text in tqdm(data['text'].astype(str).items()):\n",
    "    try:\n",
    "        chunks = split_text(text)\n",
    "        all_ents = []\n",
    "        for chunk in chunks:\n",
    "            all_ents.extend(ner_pipeline(chunk))  # 對每段跑 NER\n",
    "        for ent in all_ents:\n",
    "            ner_rows.append({\n",
    "                \"index\": idx,\n",
    "                \"entity\": ent['entity_group'],  # e.g., PER, LOC\n",
    "                \"word\": ent['word'],\n",
    "                \"score\": ent['score']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error at idx {idx}: {e}\")\n",
    "\n",
    "# 建立 DataFrame\n",
    "ner_df = pd.DataFrame(ner_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c0283",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1749736268179,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "875c0283",
    "outputId": "46797349-fcf9-44d0-ae61-13cfa2979d86"
   },
   "outputs": [],
   "source": [
    "ner_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf7dd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1749736268646,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "2cbf7dd1",
    "outputId": "210344d9-aaee-415d-f07d-d334f88c2125"
   },
   "outputs": [],
   "source": [
    "# 整合 label\n",
    "merged_df = ner_df.merge(data[['label']], left_on='index', right_index=True)\n",
    "\n",
    "# 聚合所有 entity 類型的出現次數\n",
    "entity_counts_all = (\n",
    "    merged_df.groupby(['index', 'entity'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # 得到每篇文章各類實體數\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 合併 label\n",
    "entity_counts_all = entity_counts_all.merge(data[['label']], left_on='index', right_index=True)\n",
    "\n",
    "# 建模欄位選擇：所有實體類別欄位（排除 index, label）\n",
    "feature_cols = [col for col in entity_counts_all.columns if col not in ['index', 'label']]\n",
    "kmeans_fit_pred_data = entity_counts_all[feature_cols]\n",
    "\n",
    "# 做 KMeans 聚類\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "entity_counts_all['cluster'] = kmeans.fit_predict(kmeans_fit_pred_data)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(kmeans_fit_pred_data)\n",
    "entity_counts_all['PC1'] = X_pca[:, 0]\n",
    "entity_counts_all['PC2'] = X_pca[:, 1]\n",
    "# 視覺化聚類結果\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=entity_counts_all,\n",
    "    x='PC1', y='PC2', hue='cluster', style='label',\n",
    "    palette='Set2', s=100\n",
    ")\n",
    "\n",
    "plt.title('NER 特徵的主成分分析 + KMeans 聚類')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ssZp0y9GbvTr",
   "metadata": {
    "id": "ssZp0y9GbvTr"
   },
   "source": [
    "1. 使用NER特徵進行KMeans聚類，無監督學習自動分成兩群，上圖為模型前的探索性資料分析(EDA)結果，觀察結果:KMeans聚類有部分成功聚出假新聞群，綠色cluster1幾乎都是叉叉為假新聞群，橘色cluster0包含較多真新聞與部分假新聞。\n",
    "2. 結論：分群重疊明顯，整體分群效果不算非常好，但初步判斷NER有區別能力，需結合更多特徵進行多模態聚類模型評估!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9def6",
   "metadata": {},
   "source": [
    "### 多模態特徵+分類器評估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6e5bf",
   "metadata": {
    "id": "74e6e5bf"
   },
   "source": [
    "#### A. 使用「命名實體識別(NER)」來辨識真假新聞\n",
    "使用NER當作特徵，提取出的`人名`、`組織`、`地名數量`作為詞彙特徵，加上`4個分類器(LogisticRegression、DecisionTree、SVM、RandomForest)`評估結果來分類真假新聞，預測這篇新聞是真/假。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d807d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1749736269642,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "a8d807d7",
    "outputId": "656d47cd-a303-4e63-d0e1-d01087815c65"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# ── Part 1：NER特徵模型比較 ───────────────────────────\n",
    "# === 建立特徵（NER 例子） ===\n",
    "entity_counts = ner_df.groupby(['index', 'entity']).size().unstack(fill_value=0)\n",
    "data_with_ner = data.copy()\n",
    "data_with_ner = data_with_ner.join(entity_counts, how='left').fillna(0)\n",
    "\n",
    "X = data_with_ner[['PER', 'ORG', 'LOC']]\n",
    "y = data_with_ner['label']\n",
    "\n",
    "# === 分類器列表 ===\n",
    "# classifiers = {\n",
    "#     \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "#     \"DecisionTree\": DecisionTreeClassifier(),\n",
    "#     \"SVM\": svm.SVC(probability=True),\n",
    "#     \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "classifiers = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": svm.SVC(probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# === K-fold 設定 ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 儲存平均 f1-score 結果\n",
    "results = []\n",
    "\n",
    "# === 執行交叉驗證並印出每個模型報告 ===\n",
    "for name, model in classifiers.items():\n",
    "    print(f\"\\n=== {name} 分類結果（5-fold） ===\")\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    fold_f1_scores = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        clf = clone(model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "\n",
    "        fold_f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    print(classification_report(\n",
    "        y_true_all, y_pred_all,\n",
    "        target_names=[\"真新聞\", \"假新聞\"],\n",
    "        digits=2\n",
    "    ))\n",
    "\n",
    "    results.append({\n",
    "        \"classifier\": name,\n",
    "        \"f1_weighted\": avg_f1\n",
    "    })\n",
    "\n",
    "# === 比較結果表格 ===\n",
    "result_df = pd.DataFrame(results).sort_values(by=\"f1_weighted\", ascending=False).reset_index(drop=True)\n",
    "print(\"🏁 各模型比較：\")\n",
    "print(tabulate(result_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# === 找出最佳模型 ===\n",
    "best = result_df.iloc[0]\n",
    "print(f\"\\n🏆 最佳分類器為：{best['classifier']}，weighted F1 = {best['f1_weighted']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e1c16",
   "metadata": {
    "id": "7b1e1c16"
   },
   "source": [
    "+ NER提取特徵預測結果尚可，NER特徵對真假新聞辨識有一定程度作用，`最佳分類器：SVM`，`Weighted F1 = 0.5968`。\n",
    "+ 結論：特徵太少，只有三維「人名/地名/組織」，資訊量太低。很多新聞或推文不一定包含這三類實體，變成無效資料。。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ff9f4",
   "metadata": {
    "id": "400ff9f4"
   },
   "source": [
    "#### B. 使用「情緒分析」來辨識真假新聞\n",
    "\n",
    "利用`多個情緒特徵模型進行`，加上`4個分類器(LogisticRegression、DecisionTree、SVM、RandomForest)`比較，評估最佳結果來分類真假新聞，預測這篇新聞是真/假。\n",
    "+ **情緒模型介紹：**\n",
    "1. distilbert：一款基於SST-2微調的輕量級BERT模型，常用於英文產品評論或客服對話中的情緒正負分類任務。\n",
    "2. roberta-twitter：專為Twitter資料訓練的RoBERTa模型，廣泛應用於社群貼文的輿情分析與社會事件情緒偵測。\n",
    "3. bertweet：以海量推文語料訓練的BERT模型，特別適用於社群媒體上的即時情緒追蹤與用戶反應分析。\n",
    "4. nlptown：一個支援多語言、可輸出1～5星等級的情緒強度模型，常用於多語評論評等、顧客滿意度分析等任務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d64c13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 899833,
     "status": "ok",
     "timestamp": 1749737169500,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "d3d64c13",
    "outputId": "7eded0ad-c018-4758-8b68-fd6ba73ca4b7"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ── Part 2：情緒特徵模型比較 ───────────────────────────\n",
    "sentiment_models = {\n",
    "    \"distilbert\"      : \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    \"roberta-twitter\" : \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    \"bertweet\"        : \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
    "    \"nlptown\"         : \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "}\n",
    "# sentiment_models = {\n",
    "#     \"bertweet\"        : \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "# }\n",
    "\n",
    "classifiers = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"LinearSVC\"    : LinearSVC(),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# classifiers = {\n",
    "#     \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# 使用 tokenizer 分段，每段不超過 max_tokens（不含 special tokens）\n",
    "def tokenize_chunks(text, tokenizer, max_tokens=512):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return [text]\n",
    "    chunked_tokens = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n",
    "    return [tokenizer.decode(chunk) for chunk in chunked_tokens]\n",
    "\n",
    "def split_chunks(txt, size=512):\n",
    "    return [txt[i:i+size] for i in range(0, len(txt), size)]\n",
    "\n",
    "def senti_score(txt, pipe):\n",
    "    try:\n",
    "        res = pipe(split_chunks(txt))\n",
    "        pos = [r['score'] for r in res if 'POS' in r['label'].upper()]\n",
    "        neg = [r['score'] for r in res if 'NEG' in r['label'].upper()]\n",
    "        return (sum(pos)/len(pos)) if pos and sum(pos) > sum(neg) \\\n",
    "               else -(sum(neg)/len(neg)) if neg else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "    \n",
    "# 批次處理 + 情緒得分\n",
    "def senti_score_batch(texts, model_name, batch_size=16, max_tokens=512):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    pipe = pipeline(\"sentiment-analysis\", model=model_name, device=0 if torch.cuda.is_available() else -1)\n",
    "    \n",
    "    all_scores = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Token-based Sentiment Inference\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        batch_scores = []\n",
    "\n",
    "        for text in batch:\n",
    "            try:\n",
    "                chunks = tokenize_chunks(text, tokenizer, max_tokens=max_tokens)\n",
    "                results = [pipe(chunk)[0] for chunk in chunks]  # 每段丟進 sentiment pipeline\n",
    "\n",
    "                pos = [r['score'] for r in results if 'POS' in r['label'].upper()]\n",
    "                neg = [r['score'] for r in results if 'NEG' in r['label'].upper()]\n",
    "                score = (sum(pos) / len(pos)) if pos and sum(pos) > sum(neg) \\\n",
    "                        else -(sum(neg) / len(neg)) if neg else 0.0\n",
    "            except:\n",
    "                score = 0.0\n",
    "            batch_scores.append(score)\n",
    "\n",
    "        all_scores.extend(batch_scores)\n",
    "    return all_scores\n",
    "\n",
    "def compute_sentiment_scores(texts, model_name, batch_size=32):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size)):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            # 依模型標籤格式來處理：\n",
    "            if probs.shape[1] == 3:  # eg: [NEG, NEU, POS]\n",
    "                score = (probs[:, 2] - probs[:, 0]).cpu().numpy()\n",
    "            elif probs.shape[1] == 2:  # eg: [NEG, POS]\n",
    "                score = (probs[:, 1] - probs[:, 0]).cpu().numpy()\n",
    "            else:\n",
    "                score = probs[:, 1].cpu().numpy()  # fallback\n",
    "            scores.extend(score)\n",
    "    return scores\n",
    "\n",
    "all_results, model_mean = [], []\n",
    "\n",
    "for m_key, m_name in sentiment_models.items():\n",
    "    print(f\"\\n🔍 Sentiment Model: {m_key}\")\n",
    "    data_tmp = data.copy()\n",
    "    # 修正方法\n",
    "    texts = data_tmp['text'].astype(str).tolist()\n",
    "    data_tmp['sentiment_score'] = senti_score_batch(\n",
    "        texts, model_name=m_name, batch_size=16  # 可依照 GPU 調整\n",
    "    )\n",
    "\n",
    "    X_senti = data_tmp[['sentiment_score']]\n",
    "    y       = data_tmp['label']\n",
    "\n",
    "    f1_collect = []\n",
    "    for clf_key, clf in classifiers.items():\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X_senti, y, test_size=0.2, random_state=42)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_pred = clf.predict(X_te)\n",
    "        f1_val = f1_score(y_te, y_pred, average='weighted')\n",
    "        f1_collect.append(f1_val)\n",
    "        all_results.append({\"model\": m_key, \"classifier\": clf_key, \"f1\": f1_val})\n",
    "\n",
    "    model_mean.append({\"model\": m_key, \"mean_f1\": np.mean(f1_collect)})\n",
    "\n",
    "# ➜ 找平均 F1 最高的情緒模型\n",
    "model_df = pd.DataFrame(model_mean).sort_values('mean_f1', ascending=False)\n",
    "best_senti = model_df.iloc[0]['model']\n",
    "print(\"\\n📊  情緒模型平均 F1：\")\n",
    "print(tabulate(model_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "print(f\"\\n🏆 最佳情緒模型：{best_senti}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcccc87d",
   "metadata": {
    "id": "bcccc87d"
   },
   "source": [
    "+ 結論： 情緒預測真假新聞表現不好，整體分類效果偏弱，`最佳情緒模型：distilbert`，`最佳分類器：RandomForest`，`Weighted F1 =0.74 `。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0b838",
   "metadata": {
    "id": "55e0b838"
   },
   "source": [
    "#### C. 使用「NER+情緒」來辨識真假新聞\n",
    "延續步驟B選出最佳情緒模型`distilbert`後，加上`4個分類器(LogisticRegression、DecisionTree、SVM、RandomForest)`比較。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7yrPG8mXmvfH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 232013,
     "status": "ok",
     "timestamp": 1749737401520,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "7yrPG8mXmvfH",
    "outputId": "0fc62356-f179-4a19-aca2-26bef50a20a4"
   },
   "outputs": [],
   "source": [
    "# ── Part 3：NER + Best Sentiment 特徵訓練 ──────────────\n",
    "# 1️⃣ 用最佳情緒模型重新計算 sentiment_score\n",
    "# best_pipe = pipeline(\"sentiment-analysis\", model=sentiment_models[best_senti], truncation=True, device=0 if device.type == \"cuda\" else -1)\n",
    "# tqdm.pandas()\n",
    "# data['sentiment_score'] = data['text'].astype(str).progress_apply(lambda t: senti_score(t, best_pipe))\n",
    "texts = data['text'].astype(str).tolist()\n",
    "data['sentiment_score'] = senti_score_batch(\n",
    "    texts, model_name=sentiment_models[best_senti], batch_size=16  # GPU + batch\n",
    ")\n",
    "\n",
    "# 2️⃣ 合併 NER (PER/ORG/LOC) + sentiment_score\n",
    "feature_df = data_with_ner[['PER', 'ORG', 'LOC']].join(data['sentiment_score'])\n",
    "X_full = feature_df\n",
    "y_full = data['label']\n",
    "\n",
    "# 3️⃣ 四個分類器\n",
    "final_clfs = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : svm.SVC(probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "# final_clfs = {\n",
    "#     \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_res = []\n",
    "\n",
    "for clf_key, base_clf in final_clfs.items():\n",
    "    y_all_t, y_all_p, f1_list = [], [], []\n",
    "\n",
    "    for tr_idx, te_idx in kf.split(X_full, y_full):\n",
    "        X_tr, X_te = X_full.iloc[tr_idx], X_full.iloc[te_idx]\n",
    "        y_tr, y_te = y_full.iloc[tr_idx], y_full.iloc[te_idx]\n",
    "\n",
    "        clf = clone(base_clf)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_pr = clf.predict(X_te)\n",
    "\n",
    "        y_all_t.extend(y_te); y_all_p.extend(y_pr)\n",
    "        f1_list.append(f1_score(y_te, y_pr, average='weighted'))\n",
    "\n",
    "    print(f\"\\n=== {clf_key} 整體報告 ===\")\n",
    "    print(classification_report(y_all_t, y_all_p, target_names=[\"真新聞\",\"假新聞\"], digits=2))\n",
    "\n",
    "    final_res.append({\"classifier\": clf_key, \"f1_weighted\": np.mean(f1_list)})\n",
    "\n",
    "# 4️⃣ 比較表 & 最佳分類器\n",
    "final_df = pd.DataFrame(final_res).sort_values('f1_weighted', ascending=False).reset_index(drop=True)\n",
    "print(\"\\n📊  最終 4 分類器比較：\")\n",
    "print(tabulate(final_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best_cls = final_df.iloc[0]\n",
    "print(f\"\\n🏆 最終最佳組合：情緒模型={best_senti} + 分類器={best_cls['classifier']}，weighted F1={best_cls['f1_weighted']:.4f}\")\n",
    "\n",
    "# 5️⃣ (可選) 視覺化\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=final_df, palette='Set2')\n",
    "plt.title(f'NER + Sentiment({best_senti})  4 分類器比較')\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26858d1",
   "metadata": {},
   "source": [
    "+ 結論：可在進行優化，`最佳分類器：SVM`，`Weighted F1 =0.6014 `。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2OZ3X91gvzZA",
   "metadata": {
    "id": "2OZ3X91gvzZA"
   },
   "source": [
    "#### D. 使用「NER+情緒+TFIDF」來辨識真假新聞\n",
    "延續步驟C.加入`TFIDF`，，加上`4個分類器(LogisticRegression、DecisionTree、SVM、RandomForest)`比較。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8U7BNkkiv8yI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 230421,
     "status": "ok",
     "timestamp": 1749737631960,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "8U7BNkkiv8yI",
    "outputId": "d121b30c-9bcd-4cbb-b5d0-72ea0d4f5d6e"
   },
   "outputs": [],
   "source": [
    "# ── Part 4：TF-IDF + NER + Best Sentiment 模型 ──────────────────────\n",
    "# ✅ 使用 Part 2 最佳情緒模型重新生成 sentiment_score\n",
    "senti_model_name = sentiment_models[best_senti]\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=senti_model_name, truncation=True, device=0 if device.type == \"cuda\" else -1)\n",
    "tqdm.pandas()\n",
    "data['sentiment_score'] = data['text'].astype(str).progress_apply(lambda t: senti_score(t, sentiment_pipe))\n",
    "\n",
    "# 1️⃣ 建立 TF-IDF 特徵\n",
    "tfidf_vec = TfidfVectorizer(max_features=200, ngram_range=(1, 2))\n",
    "tfidf_mat = tfidf_vec.fit_transform(data['clean_text'].fillna(''))\n",
    "tfidf_df = pd.DataFrame(tfidf_mat.toarray(),\n",
    "                        columns=tfidf_vec.get_feature_names_out(),\n",
    "                        index=data.index)\n",
    "\n",
    "# 2️⃣ 取得 NER 特徵 + 最新 sentiment 分數\n",
    "ner_df     = data_with_ner[['PER', 'ORG', 'LOC']].copy()\n",
    "senti_df   = data[['sentiment_score']]\n",
    "X_features = pd.concat([ner_df, senti_df, tfidf_df], axis=1)\n",
    "y_target   = data['label']\n",
    "\n",
    "# 3️⃣ 定義分類器\n",
    "classifiers = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : svm.SVC(probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "# classifiers = {\n",
    "#     \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# 4️⃣ Cross-Validation 訓練\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for clf_name, clf_model in classifiers.items():\n",
    "    print(f\"\\n=== {clf_name} 分類結果（5-fold） ===\")\n",
    "    y_all_true, y_all_pred, f1s = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X_features, y_target):\n",
    "        X_train, X_test = X_features.iloc[train_idx], X_features.iloc[test_idx]\n",
    "        y_train, y_test = y_target.iloc[train_idx], y_target.iloc[test_idx]\n",
    "\n",
    "        clf = clone(clf_model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        y_all_true.extend(y_test)\n",
    "        y_all_pred.extend(y_pred)\n",
    "        f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    print(classification_report(y_all_true, y_all_pred,\n",
    "                                target_names=[\"真新聞\", \"假新聞\"], digits=2))\n",
    "\n",
    "    results.append({\n",
    "        \"classifier\": clf_name,\n",
    "        \"f1_weighted\": np.mean(f1s)\n",
    "    })\n",
    "\n",
    "# 5️⃣ 輸出總結\n",
    "result_df = pd.DataFrame(results).sort_values(by='f1_weighted', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n📊 TF-IDF + NER + Sentiment 分類器比較：\")\n",
    "print(tabulate(result_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best = result_df.iloc[0]\n",
    "print(f\"\\n🏆 最佳分類器為：{best['classifier']}，weighted F1 = {best['f1_weighted']:.4f}\")\n",
    "\n",
    "# ➕ 可選視覺化\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=result_df, palette='Set3')\n",
    "plt.title(f\"TF-IDF + NER + Sentiment({best_senti}) 分類器比較\")\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3xHOBUT211bp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1749737632097,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "3xHOBUT211bp",
    "outputId": "f0ab62f9-a352-44a7-de19-5e04ffaa6af8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 依 label 分群\n",
    "true_texts = data[data['label'] == 0]['clean_text'].fillna('')\n",
    "fake_texts = data[data['label'] == 1]['clean_text'].fillna('')\n",
    "\n",
    "# 建立 TF-IDF 向量器（可使用相同設定以便比較）\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "\n",
    "# 擬合於真新聞\n",
    "true_tfidf_matrix = tfidf.fit_transform(true_texts)\n",
    "true_feature_names = tfidf.get_feature_names_out()\n",
    "true_scores = true_tfidf_matrix.mean(axis=0).A1\n",
    "true_top30 = sorted(zip(true_feature_names, true_scores), key=lambda x: x[1], reverse=True)[:30]\n",
    "\n",
    "# 擬合於假新聞（需重新建一個 vectorizer 才不會共用字典）\n",
    "tfidf_fake = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "fake_tfidf_matrix = tfidf_fake.fit_transform(fake_texts)\n",
    "fake_feature_names = tfidf_fake.get_feature_names_out()\n",
    "fake_scores = fake_tfidf_matrix.mean(axis=0).A1\n",
    "fake_top30 = sorted(zip(fake_feature_names, fake_scores), key=lambda x: x[1], reverse=True)[:30]\n",
    "\n",
    "# 將兩個 DataFrame 加上 index 並 reset\n",
    "true_df = pd.DataFrame(true_top30, columns=[\"真新聞詞\", \"真_TF-IDF\"]).reset_index(drop=True)\n",
    "fake_df = pd.DataFrame(fake_top30, columns=[\"假新聞詞\", \"假_TF-IDF\"]).reset_index(drop=True)\n",
    "\n",
    "# 合併為一個表格（左右比對）\n",
    "compare_df = pd.concat([true_df, fake_df], axis=1)\n",
    "\n",
    "# 顯示結果\n",
    "from IPython.display import display\n",
    "print(\"📊 真新聞 vs 假新聞 前 30 常見關鍵詞（TF-IDF 分數）\")\n",
    "display(compare_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1a61f",
   "metadata": {},
   "source": [
    "+ 利用TFIDF找出真假新聞常見關鍵字。\n",
    "+ 結論：加入TFIDF後，分類器效果提升，`最佳分類器：RandomForest`，`Weighted F1 = 0.8604`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S1F-x4xHLhyi",
   "metadata": {
    "id": "S1F-x4xHLhyi"
   },
   "source": [
    "#### E. 使用「NER+情緒+TFIDF」加入其他VADER&文字Style來辨識真假新聞\n",
    "延續步驟D.加入`VADER(+Empath)與文字表達Style特徵`，，加上`4個分類器(LogisticRegression、DecisionTree、SVM、RandomForest)`比較。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFDPH3NGLf7k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5075,
     "status": "ok",
     "timestamp": 1749737722134,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "SFDPH3NGLf7k",
    "outputId": "ebc5fc07-1527-4bcd-ea51-d8ca1ad15c32"
   },
   "outputs": [],
   "source": [
    "# ── Part 5：TF-IDF+NER+Sentiment特徵上，再加入VADER(+Empath)與文字表達Style特徵 ──────────────────────\n",
    "# ------------------------------------------------------------------\n",
    "# 1. 透過卡方檢定 (chi-square) 找出「假新聞 > 真新聞」最具區辨力的 n-gram\n",
    "# ------------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np, pandas as pd, re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# （1）建一個詞袋模型（unigram+bigram，過濾英文停用字, min_df=5 避免太稀有）\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "X_bow = cv.fit_transform(data['clean_text'])\n",
    "feature_names = np.array(cv.get_feature_names_out())\n",
    "\n",
    "# （2）做卡方檢定；label=1 代表假新聞\n",
    "chi_scores, _ = chi2(X_bow, data['label'])\n",
    "\n",
    "# （3）只保留在假新聞出現次數 > 真新聞的詞，再取前 30 名\n",
    "fake_mask = (X_bow[data['label'].values==1].sum(axis=0) >\n",
    "             X_bow[data['label'].values==0].sum(axis=0)).A1\n",
    "candidate_words = feature_names[fake_mask]\n",
    "candidate_scores= chi_scores[fake_mask]\n",
    "\n",
    "top_k = 30\n",
    "top_idx = np.argsort(candidate_scores)[::-1][:top_k]\n",
    "auto_clickbait = set(candidate_words[top_idx])\n",
    "\n",
    "print(f\"🔍 自動偵測到 {len(auto_clickbait)} 個假新聞高相關詞（前 {top_k}）：\")\n",
    "print(sorted(auto_clickbait))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. 建立 VADER / Empath / Style 特徵（含「動態 click-bait」）\n",
    "# ------------------------------------------------------------------\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "try:\n",
    "    from empath import Empath\n",
    "    lexicon = Empath(); use_empath = True\n",
    "except ModuleNotFoundError:\n",
    "    use_empath = False\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# 2-1 VADER\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "vader_df = (data['text'].progress_apply(vader.polarity_scores)\n",
    "                       .apply(pd.Series).add_prefix('vader_'))\n",
    "print(\"\\n🧠 VADER 情緒推動特徵（前幾筆）：\")\n",
    "print(vader_df.head())\n",
    "\n",
    "# 2-2 Empath（選擇幾個常用情緒社會面向）\n",
    "if use_empath:\n",
    "    empath_raw = data['text'].progress_apply(lambda t: lexicon.analyze(t, normalize=True))\n",
    "    empath_keep = ['positive_emotion','negative_emotion','anger','sadness',\n",
    "                   'fear','politics','money','fun','love']\n",
    "    empath_df = (pd.DataFrame(empath_raw.tolist())\n",
    "                   [empath_keep].add_prefix('empath_'))\n",
    "\n",
    "    print(\"\\n🎯 NRC-Empath 情緒向量（前幾筆）：\")\n",
    "    print(empath_df.head())\n",
    "else:\n",
    "    empath_df = pd.DataFrame(index=data.index)   # 空 DF\n",
    "    print(\"\\n⚠️ 未啟用 Empath（需 pip install empath）\")\n",
    "\n",
    "# 2-3 Style features（大寫比例 / ! 密度 / 自動 click-bait 命中率）\n",
    "def style_feats(txt:str):\n",
    "    L = max(len(txt),1)\n",
    "    txt_low = txt.lower()\n",
    "    hit_cnt = sum(1 for w in auto_clickbait if w in txt_low)\n",
    "    return pd.Series({\n",
    "        'caps_ratio'      : sum(c.isupper() for c in txt)/L,\n",
    "        'excl_ratio'      : txt.count('!')/L,\n",
    "        'clickbait_ratio' : hit_cnt / len(auto_clickbait)\n",
    "    })\n",
    "\n",
    "style_df = data['text'].progress_apply(style_feats)\n",
    "\n",
    "print(\"\\n📝 文字表達方式特徵（大寫比例 / 感嘆號密度 / Click-bait 命中率）\")\n",
    "print(style_df.describe())\n",
    "\n",
    "print(\"\\n📊 假新聞與真新聞的 Style 特徵平均比較：\")\n",
    "print(pd.concat([style_df, data['label']], axis=1)\n",
    "        .groupby('label').mean()\n",
    "        .rename(index={0: \"真新聞\", 1: \"假新聞\"}))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. 把新特徵接到既有 X_features（TF-IDF + NER + Best-Sentiment）\n",
    "# ------------------------------------------------------------------\n",
    "X_final = pd.concat([X_features, vader_df, empath_df, style_df], axis=1)\n",
    "y_final = data['label']\n",
    "print(\"🔢 新增後特徵維度 :\", X_final.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. 四個分類器 × 5-fold 交叉驗證\n",
    "# ------------------------------------------------------------------\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "clfs = {\n",
    "    \"LogReg\"      : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVM\"         : SVC(probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "# clfs = {\n",
    "#     \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "rows = []\n",
    "\n",
    "for name, base in clfs.items():\n",
    "    y_t, y_p, f1s = [], [], []\n",
    "    for tr, te in kf.split(X_final, y_final):\n",
    "        mdl = clone(base).fit(X_final.iloc[tr], y_final.iloc[tr])\n",
    "        pred = mdl.predict(X_final.iloc[te])\n",
    "        y_t.extend(y_final.iloc[te]); y_p.extend(pred)\n",
    "        f1s.append(f1_score(y_final.iloc[te], pred, average='weighted'))\n",
    "    print(f\"\\n=== {name} 報告 (加 VADER / Style) ===\")\n",
    "    print(classification_report(y_t, y_p, target_names=['真新聞','假新聞'], digits=2))\n",
    "    rows.append({\"classifier\": name, \"f1_weighted\": np.mean(f1s)})\n",
    "\n",
    "res_df = pd.DataFrame(rows).sort_values('f1_weighted', ascending=False)\n",
    "print(\"\\n📊  加 VADER / Style / 動態 Click-bait 後分類器比較\")\n",
    "print(tabulate(res_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best_cls = res_df.iloc[0]\n",
    "print(f\"\\n🏆  新最佳模型：{best_cls['classifier']}  (Weighted F1 = {best_cls['f1_weighted']:.4f})\")\n",
    "\n",
    "# （可選）長條圖\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=res_df, palette='Set2')\n",
    "plt.title('加入 VADER / Style 特徵後的分類器比較')\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0,1); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903532f7",
   "metadata": {},
   "source": [
    "+ 結論：引入VADER情緒分析與文字風格特徵，以強化假新聞與真新聞的語言表徵差異，經以上模型測試，**使用「NER+情緒+TFIDF+VADER+STYLE」特徵的結果最好**，`最佳分類器：RandomForest`，`Weighted F1 =0.8675 `。\n",
    "+ 從VADER特徵結果可見，假新聞整體偏向產生較高的負向情緒分數與極端情感（compound 分數較負），顯示假新聞傾向以情緒性語言激發讀者反應。另一方面，文字表達方式方面的比較顯示，假新聞在大寫字母使用比例（caps_ratio）、感嘆號密度（excl_ratio）、以及 clickbait 關鍵詞命中率（clickbait_ratio）均高於真新聞，顯示假新聞常透過誇張標題與視覺強調以吸引注意力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kXCGLyxag7DL",
   "metadata": {
    "id": "kXCGLyxag7DL"
   },
   "source": [
    "#### F. 使用「NER+情緒+SBERT」來辨識真假新聞\n",
    "+ 利用SBERT向量化方式與步驟D的TFIDF比較，，再加上`4個分類器(LogisticRegression、DecisionTree、SVM、RandomForest)`評估最佳結果。\n",
    "+ 經前測結果，採用此模型`sentence-transformers/paraphrase-MiniLM-L6-v2`進行。\n",
    "1. 使用all-MiniLM-L6-v2，最佳分類器為：RandomForest，Weighted F1 = 0.7197\n",
    "2. 使用sentence-transformers/paraphrase-MiniLM-L6-v2，最佳分類器為：LogReg，Weighted F1 = 0.7467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RRiE1c9WgFLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1bd81346eb5446ae86c8992ea87a8979",
      "3aa0234db1f4447da06ae0ba78593276",
      "aaefd6793ed644b3afbf183bec859bff",
      "e108b8551f0e41b69ce386e7cbdf3945",
      "9c0fc22fc33a4388b5cde67492782329",
      "a7bd128141e746019bbd9eeed16eda0c",
      "c9da9c06c90a475ab7e45abc95f3dec3",
      "953dd787d72045bc9382fef65869ced1",
      "30cfa6df7235440a8aaf12b38e7c1a24",
      "2ff3e28618eb412c9f1879564137be6c",
      "07b0a05b872c48ec8bc00ec063304866"
     ]
    },
    "executionInfo": {
     "elapsed": 13099,
     "status": "ok",
     "timestamp": 1749738724842,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "RRiE1c9WgFLd",
    "outputId": "3b0c94d7-cadd-4537-9858-96bf4b02f141"
   },
   "outputs": [],
   "source": [
    "# ────── Part 6：NER+Sentiment特徵+SBERT向量化 ──────────────────────\n",
    "# ▍1. SBERT 向量化\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')  # 可改其他如 'paraphrase-MiniLM-L6-v2'\n",
    "sbert_embeddings = model.encode(data['clean_text'].fillna(''), show_progress_bar=True)\n",
    "\n",
    "sbert_df = pd.DataFrame(sbert_embeddings, index=data.index)\n",
    "sbert_df.columns = sbert_df.columns.astype(str)\n",
    "print(\"📐 向量維度：\", sbert_df.shape)\n",
    "\n",
    "# ▍2. 合併其他特徵（NER + Sentiment）\n",
    "ner_df    = data_with_ner[['PER', 'ORG', 'LOC']].copy()\n",
    "senti_df  = data[['sentiment_score']]\n",
    "X_sbert   = pd.concat([sbert_df, ner_df, senti_df], axis=1)\n",
    "y_target  = data['label']\n",
    "\n",
    "# ▍3. 建立分類器組合\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.base import clone\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "classifiers = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : SVC(probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "# classifiers = {\n",
    "#     \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# ▍4. Cross-validation 比較表現\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for clf_name, clf_model in classifiers.items():\n",
    "    print(f\"\\n=== {clf_name} 分類結果（5-fold） ===\")\n",
    "    y_all_true, y_all_pred, f1s = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X_sbert, y_target):\n",
    "        X_train, X_test = X_sbert.iloc[train_idx], X_sbert.iloc[test_idx]\n",
    "        y_train, y_test = y_target.iloc[train_idx], y_target.iloc[test_idx]\n",
    "\n",
    "        clf = clone(clf_model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        y_all_true.extend(y_test)\n",
    "        y_all_pred.extend(y_pred)\n",
    "        f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=[\"真新聞\", \"假新聞\"], digits=2))\n",
    "\n",
    "    results.append({\n",
    "        \"classifier\": clf_name,\n",
    "        \"f1_weighted\": np.mean(f1s)\n",
    "    })\n",
    "\n",
    "# ▍5. 顯示比較結果\n",
    "result_df = pd.DataFrame(results).sort_values(by='f1_weighted', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n📊 SBERT + NER + Sentiment 分類器比較：\")\n",
    "print(tabulate(result_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best = result_df.iloc[0]\n",
    "print(f\"\\n🏆 最佳分類器為：{best['classifier']}，weighted F1 = {best['f1_weighted']:.4f}\")\n",
    "\n",
    "# ▍6. 視覺化結果\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=result_df, palette='Set2')\n",
    "plt.title(\"BERT 向量 + NER + Sentiment 分類器比較\")\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HbkktXE-jqDV",
   "metadata": {
    "id": "HbkktXE-jqDV"
   },
   "source": [
    "+ 結論：表現成果沒有步驟E使用「NER+情緒+TFIDF+VADER+文字Style」的好，`最佳分類器：SVM`，`Weighted F1 =0.8612 `。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff48406",
   "metadata": {},
   "source": [
    "#### **G. 最佳多特徵模型為：使用「NER+情緒分數+TFIDF+VADER+文字Style」最好**\n",
    "`最佳分類器：RandomForest`，`Weighted F1 =0.8675 `。利用此結果往下進行Bertopic作業"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa66961",
   "metadata": {
    "id": "2aa66961"
   },
   "source": [
    "## 三、主題模型：BERTopic \n",
    "+ 依最佳向量化策略(TFIDF+Style)建立HDBSCAN聚類，並輸出「真假比例最高/最低」主題與關鍵字。\n",
    "+ 步驟：使用最佳向量化結果(TFIDF+VADER+文字Style)→BERTopic分群→疊加真假標籤→看每個主題哪邊假新聞高、哪邊真新聞高，這樣就能得到：\n",
    "  1. 假新聞最常見的主題有哪些?\n",
    "  2. 真新聞裡哪些主題特別突出?\n",
    "  3. 各主題的代表關鍵詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gmCYJY1vm9EW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1611,
     "status": "ok",
     "timestamp": 1749741036530,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "gmCYJY1vm9EW",
    "outputId": "5b1a8b04-f301-4c61-8191-b9a0d51b4ed1"
   },
   "outputs": [],
   "source": [
    "# -------- 1. 選擇向量化方式 -------------------------------------Part 4 / 5 / 6 結果輸入\n",
    "VEC_CHOICE = \"tfidf_style\"       # ← 輸入 # Part 4- \"tfidf\" / Part 5- \"tfidf_style\" / Part 6- \"sbert\"\n",
    "texts = data['clean_text'].fillna('')\n",
    "\n",
    "if VEC_CHOICE == \"tfidf\":\n",
    "    vec_model = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=\"english\")\n",
    "    embeddings = vec_model.fit_transform(texts)\n",
    "\n",
    "elif VEC_CHOICE == \"tfidf_style\":\n",
    "    if \"X_final\" not in globals():\n",
    "        raise RuntimeError(\"⚠️ 找不到 X_final，請先執行 Part 5 建立特徵\")\n",
    "    embeddings = X_final.values\n",
    "\n",
    "elif VEC_CHOICE == \"sbert\":\n",
    "    emb_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "    embeddings = emb_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"VEC_CHOICE 僅能為 'tfidf' / 'tfidf_style' / 'sbert'\")\n",
    "\n",
    "# -------- 2. 建立 BERTopic 模型 ----------------------------------\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=None if VEC_CHOICE.startswith(\"tfidf\") else emb_model,\n",
    "    hdbscan_model=HDBSCAN(min_cluster_size=10, min_samples=30),\n",
    "    vectorizer_model=CountVectorizer(ngram_range=(1, 2), stop_words=\"english\"),\n",
    "    calculate_probabilities=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, _ = topic_model.fit_transform(texts, embeddings)\n",
    "data['topic'] = topics\n",
    "\n",
    "# ✅ 防呆：確認是否有有效主題（非 -1）\n",
    "valid_topics = [t for t in set(topics) if t != -1]\n",
    "if len(valid_topics) == 0:\n",
    "    print(\"⚠️ 無有效主題（全部為 outlier），請檢查資料筆數或降低 min_cluster_size 設定。\")\n",
    "else:\n",
    "    # -------- 3. 主題 × 真／假 分佈 -------------------------------\n",
    "    data['label_name'] = data['label'].map({0: \"True\", 1: \"Fake\"})\n",
    "    topic_dist = (data.groupby(['topic', 'label_name']).size().unstack(fill_value=0))\n",
    "    topic_dist['Total'] = topic_dist.sum(axis=1)\n",
    "    topic_dist['Fake_Ratio'] = topic_dist['Fake'] / topic_dist['Total']\n",
    "\n",
    "    print(\"▶ 各 Topic 真／假筆數與假新聞比例 (前 10)：\")\n",
    "    display(topic_dist.sort_values('Fake_Ratio', ascending=False).head(10))\n",
    "\n",
    "    # -------- 4. 取主題關鍵字並依真假比例排序 ----------------------\n",
    "    kw_rows = []\n",
    "    for tid, word_scores in topic_model.get_topics().items():\n",
    "        if tid == -1:\n",
    "            continue\n",
    "        for word, score in word_scores:\n",
    "            kw_rows.append({\"topic\": tid, \"word\": word, \"c_tf_idf\": score})\n",
    "\n",
    "    kw_df = pd.DataFrame(kw_rows)\n",
    "\n",
    "    merged_kw = kw_df.merge(topic_dist.reset_index(), on=\"topic\")\n",
    "\n",
    "    fake_top_kw = (merged_kw.sort_values(['Fake_Ratio', 'c_tf_idf'], ascending=[False, False])\n",
    "                            .groupby('topic')\n",
    "                            .head(30))\n",
    "\n",
    "    true_top_kw = (merged_kw.sort_values(['Fake_Ratio', 'c_tf_idf'], ascending=[True, False])\n",
    "                            .groupby('topic')\n",
    "                            .head(30))\n",
    "\n",
    "    print(\"\\n🟥 假新聞高比例主題關鍵字 TOP 30\")\n",
    "    display(fake_top_kw[['topic', 'word', 'c_tf_idf', 'Fake_Ratio']])\n",
    "\n",
    "    print(\"\\n🟦 真新聞高比例主題關鍵字 TOP 30\")\n",
    "    display(true_top_kw[['topic', 'word', 'c_tf_idf', 'Fake_Ratio']])\n",
    "\n",
    "    # -------- 5. 視覺化每個主題的假新聞比例 ------------------------\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    sns.barplot(x=topic_dist.index, y=topic_dist['Fake_Ratio'], palette=\"coolwarm\")\n",
    "    plt.title(\"Fake-News Ratio per Topic\")\n",
    "    plt.ylabel(\"Fake Ratio\")\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "osakI7pZsZuG",
   "metadata": {
    "id": "osakI7pZsZuG"
   },
   "source": [
    "+ **結論**\n",
    "+ 透過BERTopic主題建模，採用加入情緒與Style特徵的向量進行分析，揭露假新聞與真新聞分布於主題空間的顯著差異。結果顯示，多個主題呈現高度偏向假新聞（Fake Ratio = 1.0），其中包含與政治人物（如 rick perry、american male）或具爭議性的主張（如 birthright citizenship）相關之主題，凸顯假新聞常聚焦於特定敏感議題以吸引讀者注意。\n",
    "+ 真新聞比例較高之主題則較多涵蓋中性事件與資訊報導（如 joe exotic、wildfire、pardoned），顯示其內容傾向客觀描述且情緒操弄程度較低。\n",
    "+ 從「每個主題的假新聞比例視覺化圖」可進一步觀察主題分布的極化現象，其中部分主題集中呈現極高或極低的假新聞比例，驗證主題模型能有效捕捉新聞真偽傾向。\n",
    "+ 綜合上述，加入情緒與Style向量特徵後所建構之主題模型，提升了主題Topic的字彙區辨能力，也有助於從主題角度理解真假新聞常出現的字彙。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5762b28",
   "metadata": {},
   "source": [
    "## 四、LLM ##\n",
    "\n",
    "三個本地模型分別扮演不同角色：\n",
    "- logic_llm：邏輯面判斷者(LLaMA)\n",
    "- debater_llm：辯論立場提出者(Mistral)\n",
    "- judge_llm：原始仲裁者，同時也負責最終決策(Phi-3)\n",
    "\n",
    "\n",
    "這三個模型會同時針對同一則訊息進行判斷，輸出 verdict, confidence, reason 三欄 JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama  # 使用 Ollama 封裝的 LLaMA 模型\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 定義輸出結構\n",
    "\n",
    "\n",
    "class MessageClassification(BaseModel):\n",
    "    verdict: str = Field(\n",
    "        description=\"Verdict whether the message is Real or Fake\")\n",
    "    confidence: str = Field(\n",
    "        description=\"Confidence level of the judgment (e.g., High, Medium, Low)\")\n",
    "    reason: str = Field(description=\"Brief explanation of the judgment\")\n",
    "\n",
    "\n",
    "# 使用本地 LLaMA 模型\n",
    "judge_llm = ChatOllama(model=\"llama3:8B\")\n",
    "logic_llm = ChatOllama(model=\"phi3:3.8B\")\n",
    "debater_llm = ChatOllama(model=\"mistral:7B\")\n",
    "\n",
    "# Json 輸出格式解析器\n",
    "parser = JsonOutputParser(pydantic_object=MessageClassification)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# 單一 LLM 推理的 Prompt\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a professional fact-checker. Analyze the following message and determine if it is real or fake.\n",
    "\n",
    "Message:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\n",
    "Respond **strictly** in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"verdict\": \"\",        // Only \"Real\" or \"Fake\"\n",
    "  \"confidence\": \"\",     // Only \"High\", \"Medium\", or \"Low\"\n",
    "  \"reason\": \"\"          // A short explanation (1-2 sentences)\n",
    "}}\n",
    "\n",
    "❗ Instructions:\n",
    "- Your response MUST be valid JSON. Do not include any other text.\n",
    "- Do NOT wrap the output in markdown (e.g., do NOT use ```json or any backticks).\n",
    "- Do NOT explain your answer outside the JSON.\n",
    "- Output only the JSON object with exactly three string fields: verdict, confidence, and reason.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 讓 judge_llm 匯總所有模型觀點的 Prompt\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are the final arbiter. Three experts have evaluated the message. Please summarize their opinions and give your final decision.\n",
    "\n",
    "Message:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\n",
    "Expert 1 (Logic-focused model):\n",
    "{logic_opinion}\n",
    "\n",
    "Expert 2 (Debate-focused model):\n",
    "{debate_opinion}\n",
    "\n",
    "Expert 3 (Your own opinion):\n",
    "{your_opinion}\n",
    "\n",
    "Now summarize the opinions, resolve any conflicts, and provide a final classification in this JSON format:\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc0a6b",
   "metadata": {},
   "source": [
    "仲裁模型角色說明：\n",
    "輸入: 原始訊息 data[text]\n",
    "\n",
    "對象: llama3:8B、phi3:3.8B、mistral:7B\n",
    "\n",
    "得到: 三個模型的觀點\n",
    "\n",
    "見整合這三份觀點，根據summary prompt回傳一組新的 JSON作為最後答案\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a57b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(text: str) -> dict:\n",
    "    try:\n",
    "        \n",
    "        # 找出第一組結構為 { ... } 的JSON區塊\n",
    "        match = re.search(r'{[\\s\\S]*?}', text)\n",
    "        if not match:\n",
    "            print(\"⚠️ 無有效 JSON 區塊，跳過此輸出。\")\n",
    "            print(\"原始輸出：\", text)\n",
    "            return {\n",
    "                \"verdict\": \"Unknown\",\n",
    "                \"confidence\": \"Low\",\n",
    "                \"reason\": \"Model did not return valid JSON block.\"\n",
    "            }\n",
    "        json_str = match.group()\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\n JSON 解析失敗：{e}\")\n",
    "        print(\"原始輸出：\", text)\n",
    "        return {\n",
    "            \"verdict\": \"Unknown\",\n",
    "            \"confidence\": \"Low\",\n",
    "            \"reason\": \"Model did not return valid JSON.\"\n",
    "        }\n",
    "\n",
    "def call_llm(llm, prompt):\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if hasattr(response, \"content\") else response\n",
    "\n",
    "# 定義分析函式\n",
    "def analyze_message_with_multi_llm(message: str):\n",
    "    logic_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "    debate_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "    judge_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {\n",
    "            executor.submit(call_llm, logic_llm, logic_input): \"logic\",\n",
    "            executor.submit(call_llm, debater_llm, debate_input): \"debate\",\n",
    "            executor.submit(call_llm, judge_llm, judge_input): \"judge\"\n",
    "        }\n",
    "        results = {}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            key = futures[future]\n",
    "            results[key] = future.result()\n",
    "\n",
    "    summary_input = summary_prompt.format(\n",
    "        message=message,\n",
    "        logic_opinion=results[\"logic\"],\n",
    "        debate_opinion=results[\"debate\"],\n",
    "        your_opinion=results[\"judge\"],\n",
    "        format_instructions=format_instructions\n",
    "    )\n",
    "\n",
    "    final_response = judge_llm.invoke(summary_input)\n",
    "    result = extract_json(final_response.content)\n",
    "    return result\n",
    "\n",
    "# 6/17 batch實作\n",
    "# ========== Batch呼叫llm ==========\n",
    "\n",
    "def batch_call_llm(llm, messages: list, batch_size: int, model_name: str) -> list:\n",
    "    outputs = []\n",
    "    for i in tqdm(range(0, len(messages), batch_size), desc=f\"Batching {model_name}\"):\n",
    "        batch = messages[i:i+batch_size]\n",
    "        prompts = [llm_prompt.format(message=msg, format_instructions=format_instructions) for msg in batch]\n",
    "        results = llm.batch(prompts)\n",
    "        outputs.extend([res.content if hasattr(res, \"content\") else res for res in results])\n",
    "    return outputs\n",
    "\n",
    "# ========== batch主流程 ==========\n",
    "# 先粗略根據模型餐數量大小分batch量\n",
    "def process_data_in_batches(df: pd.DataFrame, batch_logic=32, batch_debate=16, batch_judge=8) -> pd.DataFrame:\n",
    "    messages = df[\"text\"].tolist()\n",
    "    logic_results = batch_call_llm(logic_llm, messages, batch_logic, model_name=\"logic_llm\")\n",
    "    debate_results = batch_call_llm(debater_llm, messages, batch_debate, model_name=\"debater_llm\")\n",
    "    judge_results = batch_call_llm(judge_llm, messages, batch_judge, model_name=\"judge_llm\")\n",
    "\n",
    "    final_results = []\n",
    "    for i in tqdm(range(len(messages)), desc=\"Final summarization\"):\n",
    "        summary_input = summary_prompt.format(\n",
    "            message=messages[i],\n",
    "            logic_opinion=logic_results[i],\n",
    "            debate_opinion=debate_results[i],\n",
    "            your_opinion=judge_results[i],\n",
    "            format_instructions=format_instructions\n",
    "        )\n",
    "        final_response = judge_llm.invoke(summary_input)\n",
    "        parsed = extract_json(final_response.content)\n",
    "        final_results.append(parsed)\n",
    "\n",
    "    return pd.DataFrame(final_results)\n",
    "\n",
    "# ========== encode ==========\n",
    "\n",
    "def encode_verdict(verdict: str) -> int:\n",
    "    if verdict.strip().lower() == 'real':\n",
    "        return 1\n",
    "    elif verdict.strip().lower() == 'fake':\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 # 代表 Unknown 或其他無效輸入\n",
    "\n",
    "def encode_confidence(conf: str) -> int:\n",
    "    mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "    return mapping.get(conf.strip().lower(), 1)  # 預設給信心程度1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4378c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # 觀察測試用!!!\n",
    "# sample_texts = data['text'].sample(10, random_state=42)\n",
    "\n",
    "# for i, text in enumerate(sample_texts):\n",
    "#     result = analyze_message_with_multi_llm(text)\n",
    "#     print(\"推論結果：\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09167dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所需時間太長，故使用較小資料集\n",
    "\n",
    "# === 隨機抽樣 200 筆原始資料 ===\n",
    "# sampled_indices = data.sample(n=200, random_state=42).index\n",
    "\n",
    "# sampled_data = data.loc[sampled_indices]\n",
    "# X_final_sampled = X_final.loc[sampled_indices]\n",
    "# y_final_sampled = y_final.loc[sampled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aad227",
   "metadata": {},
   "source": [
    "### 根據 LLM response 新增資料欄位 ###\n",
    "\n",
    "經過prompt定義、JSON過濾器，每一筆資料預期得到類似以下結構response:\n",
    "{\n",
    "    \"verdict\": \"Real\", \n",
    "    \"confidence\": \"High\", \n",
    "    \"reason\": \"\"\n",
    "}\n",
    "\n",
    "提出verdict、confidence欄位並各自做encode，再新增進要拿來訓練的資料做為新的欄位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-LLM\n",
    "# llm_results = data['text'].progress_apply(analyze_message_with_multi_llm)\n",
    "# llm_df = pd.DataFrame(llm_results.tolist())\n",
    "\n",
    "# 改成批次處理版本process_data_in_batches\n",
    "llm_df = process_data_in_batches(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a57b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and \n",
    "def clean_verdict(v):\n",
    "    if isinstance(v, list):\n",
    "        # 尋找第一個非空字串\n",
    "        for item in v:\n",
    "            if isinstance(item, str) and item.strip():\n",
    "                return item\n",
    "        return 'Unknown'\n",
    "    elif isinstance(v, str):\n",
    "        return v\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "def clean_confidence(c):\n",
    "    if isinstance(c, list):\n",
    "        for item in c:\n",
    "            if isinstance(item, str) and item.lower() in ['low', 'medium', 'high']:\n",
    "                return item\n",
    "        return 'medium'  # fallback\n",
    "    elif isinstance(c, str):\n",
    "        return c\n",
    "    else:\n",
    "        return 'medium'\n",
    "\n",
    "llm_df['verdict_clean'] = llm_df['verdict'].apply(clean_verdict)\n",
    "llm_df['verdict_encoded'] = llm_df['verdict_clean'].apply(encode_verdict)\n",
    "\n",
    "llm_df['confidence_clean'] = llm_df['confidence'].apply(clean_confidence)\n",
    "llm_df['confidence_encoded'] = llm_df['confidence_clean'].apply(encode_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b62fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 multi-llm 討論的結果\n",
    "# 篩掉 verdict_encoded == 2 (multi-llm 回傳有問題)的樣本\n",
    "valid_mask = llm_df['verdict_encoded'] != 2\n",
    "\n",
    "llm_df_filtered = llm_df.loc[valid_mask].reset_index(drop=True)\n",
    "X_final_filtered = X_final_sampled.iloc[valid_mask.values].reset_index(drop=True)\n",
    "y_final_filtered = y_final_sampled.iloc[valid_mask.values].reset_index(drop=True)\n",
    "\n",
    "X_final_filtered = pd.concat([X_final_filtered, llm_df_filtered[['verdict_encoded', 'confidence_encoded']]], axis=1)\n",
    "\n",
    "# 如果 X_final_filtered 已有 'verdict_encoded' 先刪掉\n",
    "if 'verdict_encoded' in X_final_filtered.columns:\n",
    "    X_final_filtered = X_final_filtered.drop(columns=['verdict_encoded'])\n",
    "if 'confidence_encoded' in X_final_filtered.columns:\n",
    "    X_final_filtered = X_final_filtered.drop(columns=['confidence_encoded'])\n",
    "\n",
    "# 再加上新的欄位\n",
    "X_final_filtered = pd.concat([X_final_filtered, llm_df_filtered[['verdict_encoded', 'confidence_encoded']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f44577",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_final_filtered.columns[X_final_filtered.columns.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa6e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_final_filtered.shape)\n",
    "print(y_final_filtered.shape)\n",
    "print(X_final_filtered.isna().sum().sort_values(ascending=False).head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "# from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # classifier models\n",
    "# classifier_model = {\n",
    "#     \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "#     \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "#     \"SVM\"          : SVC(kernel='linear', probability=True),\n",
    "#     \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# scoring = {\n",
    "#     'accuracy': make_scorer(accuracy_score),\n",
    "#     'f1': make_scorer(f1_score),\n",
    "#     'precision': make_scorer(precision_score),\n",
    "#     'recall': make_scorer(recall_score)\n",
    "# }\n",
    "\n",
    "# # === init result ===\n",
    "# results = []\n",
    "\n",
    "# # === 建立 Stratified K-Fold ===\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # === 訓練每個模型 ===\n",
    "# for name, model in classifier_model.items():\n",
    "#     print(f\"\\n 訓練模型: {name}\")\n",
    "#     pipeline = Pipeline([\n",
    "#         ('scaler', StandardScaler()),  # 對所有特徵標準化\n",
    "#         ('clf', model)\n",
    "#     ])\n",
    "#     scores = cross_validate(pipeline, X_final, y_final, cv=cv, scoring=scoring)\n",
    "#     result = {\n",
    "#         'model': name,\n",
    "#         'accuracy': np.mean(scores['test_accuracy']),\n",
    "#         'f1': np.mean(scores['test_f1']),\n",
    "#         'precision': np.mean(scores['test_precision']),\n",
    "#         'recall': np.mean(scores['test_recall'])\n",
    "#     }\n",
    "#     results.append(result)\n",
    "\n",
    "# # === 整理成 DataFrame 顯示 ===\n",
    "# result_df = pd.DataFrame(results)\n",
    "# print(\"\\n各模型評估結果：\")\n",
    "# print(result_df.sort_values(by='f1', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe4b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# === Init ===\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics_list = []\n",
    "\n",
    "# === 開始交叉驗證 ===\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_final_filtered, y_final_filtered)):\n",
    "    X_train, X_test = X_final_filtered.iloc[train_idx], X_final_filtered.iloc[test_idx]\n",
    "    y_train, y_test = y_final_filtered.iloc[train_idx], y_final_filtered.iloc[test_idx]\n",
    "    \n",
    "    # 初始化 LGBM 模型\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',  # 若 label 不平衡可以開啟\n",
    "    )\n",
    "    \n",
    "    # 模型訓練\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # 預測與評估\n",
    "    y_pred = clf.predict(X_test)\n",
    "    metrics = {\n",
    "        'fold': fold + 1,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred)\n",
    "    }\n",
    "    print(f\"\\n📋 Fold {fold+1} classification report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"真新聞\", \"假新聞\"]))\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "# === 結果總覽 ===\n",
    "df_result = pd.DataFrame(metrics_list)\n",
    "print(\"\\n📊 LightGBM - K-Fold 效能比較：\")\n",
    "print(tabulate(df_result, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "# === 平均表現 ===\n",
    "avg_metrics = df_result.drop('fold', axis=1).mean().to_dict()\n",
    "print(\"\\n🏁 LightGBM 平均效能:\")\n",
    "for m, v in avg_metrics.items():\n",
    "    print(f\"{m:10}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9daad09",
   "metadata": {},
   "source": [
    "+ **結論**\n",
    "+ 經過三個LLM(LLaMA3:8b,Phi-3:3.8b,Mistral:7b)Multi-LLM仲裁模式（Arbitration Mode）結果，使用LightGBM分類器產出最終結果，F1為0.6620。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60babe86",
   "metadata": {},
   "source": [
    "## **五、最終結論** ##\n",
    "+ 真假新聞的預測，**使用「NER+情緒+TFIDF+VADER+STYLE」特徵的結果最好**，`最佳分類器：RandomForest`，`Weighted F1 =0.8675 `。\n",
    "+ 在分類器表現上，傳統的分類器表現，比LLM表現結果佳，比起原本預期LLM的表現可能會大幅優於傳統分類器的訓練表現。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b2b75",
   "metadata": {},
   "source": [
    "## 六、未來展望 ##\n",
    "\n",
    "+ 在特徵選擇方面，目前我們以人工觀察與經驗判斷方式決定特徵的保留與否，但這樣不是系統性的尋找最優特徵組合。未來可考慮使用如 sklearn.feature_selection 中的 RFE 方法，根據模型權重逐步剔除不重要的特徵。需注意此改動可能耗費大量時間；以本專案為例，目前使用全部資料集與 GPU 運行下，約需 12 小時左右，改動後可能耗費更多時間。\n",
    "\n",
    "+ 我們最終採用類似 Multi-Agent 的概念，使用多個 LLM 建構「仲裁模式」以提升判斷準確性。考量運算效率，目前採用的做法為將多筆資料批次輸入同一個 LLM，雖能稍微加快速度，卻可能降低推理品質（因非逐筆討論、上下文、前後對話順序影響）。此外，角色設定的 prompt 較為簡略，後續可考慮加入更多角色、多段思考（如 CoT）、以及新增一個 LLM 專門用來審查前段推理邏輯的正確性，進一步強化整體判斷流程的嚴謹性。\n",
    "\n",
    "+ 在實作仲裁模式的過程中，因推理耗時過長，最終改以隨機抽樣 200 筆資料進行推論（使用指令：`sampled_indices = data.sample(n=200, random_state=42).index`）。\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07b0a05b872c48ec8bc00ec063304866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bd81346eb5446ae86c8992ea87a8979": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3aa0234db1f4447da06ae0ba78593276",
       "IPY_MODEL_aaefd6793ed644b3afbf183bec859bff",
       "IPY_MODEL_e108b8551f0e41b69ce386e7cbdf3945"
      ],
      "layout": "IPY_MODEL_9c0fc22fc33a4388b5cde67492782329"
     }
    },
    "2ff3e28618eb412c9f1879564137be6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30cfa6df7235440a8aaf12b38e7c1a24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3aa0234db1f4447da06ae0ba78593276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7bd128141e746019bbd9eeed16eda0c",
      "placeholder": "​",
      "style": "IPY_MODEL_c9da9c06c90a475ab7e45abc95f3dec3",
      "value": "Batches: 100%"
     }
    },
    "953dd787d72045bc9382fef65869ced1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c0fc22fc33a4388b5cde67492782329": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7bd128141e746019bbd9eeed16eda0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaefd6793ed644b3afbf183bec859bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953dd787d72045bc9382fef65869ced1",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30cfa6df7235440a8aaf12b38e7c1a24",
      "value": 5
     }
    },
    "c9da9c06c90a475ab7e45abc95f3dec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e108b8551f0e41b69ce386e7cbdf3945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ff3e28618eb412c9f1879564137be6c",
      "placeholder": "​",
      "style": "IPY_MODEL_07b0a05b872c48ec8bc00ec063304866",
      "value": " 5/5 [00:09&lt;00:00,  1.28s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
