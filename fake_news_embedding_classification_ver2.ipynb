{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2077866c",
   "metadata": {
    "id": "2077866c"
   },
   "source": [
    "# BERT (Encoder-only-model)\n",
    "\n",
    "- Token classification\n",
    "    NER\n",
    "- Sequence classification\n",
    "    Sentiment Classification\n",
    "    Relation Extraction (RE)\n",
    "- Text Clustering (BERTopic)\n",
    "    Embedding model\n",
    "    Clustering model\n",
    "    使用Representation方法去微調主題表示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950fcec1",
   "metadata": {
    "id": "950fcec1"
   },
   "source": [
    "### 真假新聞資料集 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kHUIVdFdFJao",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134968,
     "status": "ok",
     "timestamp": 1749735935449,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "kHUIVdFdFJao",
    "outputId": "deb6b7b0-f9dc-46cd-af8d-cd7666eb0045"
   },
   "outputs": [],
   "source": [
    "# 🔧 安裝核心資料處理與模型套件\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn tqdm nltk vaderSentiment empath tabulate\n",
    "# 🔎 安裝 BERT 相關（transformers, pipeline）\n",
    "!pip install transformers\n",
    "# 🤖 安裝命名實體辨識用預訓練模型\n",
    "!pip install torch\n",
    "# 🧠 安裝情緒分析微調模型\n",
    "!pip install sentence-transformers\n",
    "# 📊 安裝主題建模：BERTopic + HDBSCAN（支援 clustering）\n",
    "!pip install bertopic hdbscan\n",
    "# 🗂 字體設定用（如你加載了自訂字體）\n",
    "!pip install fonttools\n",
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6tH_lAhbB52g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1749735936684,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "6tH_lAhbB52g",
    "outputId": "3ae7508e-acfd-43ae-a181-896ef1253e17"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gznsm2NL0XSg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1749735937812,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "gznsm2NL0XSg",
    "outputId": "f060f513-6ccf-412d-9d36-666a6c67f04b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk, ssl, os\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "nltk.data.path.extend([\n",
    "    '/usr/nltk_data',\n",
    "    '/usr/local/nltk_data',\n",
    "    '/usr/share/nltk_data',\n",
    "    '/usr/local/share/nltk_data',\n",
    "    '/root/nltk_data'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b54574",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1749735938072,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "59b54574",
    "outputId": "5392bcac-87d5-4327-b9fb-5b10e98dc092"
   },
   "outputs": [],
   "source": [
    "# 載入資料集\n",
    "fake_df = pd.read_csv('./raw_data/fake.csv')\n",
    "            #/content/drive/MyDrive/Colab Notebooks/期末專案/raw_data/Fake.csv #/content/drive/MyDrive/Colab Notebooks/期末專案/test_data/Fake_Sample.csv\n",
    "true_df = pd.read_csv('./raw_data/true.csv')\n",
    "            #/content/drive/MyDrive/Colab Notebooks/期末專案/raw_data/True.csv #/content/drive/MyDrive/Colab Notebooks/期末專案/test_data/True_Sample.csv\n",
    "\n",
    "# 合併 title 和 text 成新的 text 欄位\n",
    "fake_df['text'] = fake_df['title'].astype(str) + \" \" + fake_df['text'].astype(str)\n",
    "true_df['text'] = true_df['title'].astype(str) + \" \" + true_df['text'].astype(str)\n",
    "\n",
    "# 加上 label 欄位\n",
    "fake_df['label'] = 1\n",
    "true_df['label'] = 0\n",
    "\n",
    "# 取前 1000 筆\n",
    "dataNum = 50\n",
    "news_data = pd.concat([fake_df.iloc[:dataNum], true_df.iloc[:dataNum]], ignore_index=True)\n",
    "\n",
    "# 移除空值並只保留 text 和 label 欄位\n",
    "news_data = news_data[news_data['text'].notna()].reset_index(drop=True)\n",
    "news_data = news_data[['text', 'label']]\n",
    "\n",
    "# 檢查各類別數量\n",
    "print(news_data['label'].value_counts())\n",
    "print(news_data.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8c468",
   "metadata": {
    "id": "18a8c468"
   },
   "source": [
    "### 推特真假推文資料集 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7806f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1749735938208,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "1c7806f2",
    "outputId": "ef86ba43-79ee-452b-e3c0-ed6fc9b7522e"
   },
   "outputs": [],
   "source": [
    "# 推特資料處理(為了嘗試解決 加入TF-IDF過擬合&embed過強 可能是因為文本特徵太明顯的問題)\n",
    "tweet_df = pd.read_csv('./raw_data/Truth_Seeker_Model_Dataset_unindex.csv', encoding='ISO-8859-1')\n",
    "            #/content/drive/MyDrive/Colab Notebooks/期末專案/raw_data/Truth_Seeker_Model_Dataset.csv #/content/drive/MyDrive/Colab Notebooks/期末專案/test_data/Truth_Seeker_Model_Dataset_Sample.csv\n",
    "tweet_data = tweet_df[['BinaryNumTarget', 'tweet', '5_label_majority_answer']].copy()\n",
    "\n",
    "# 清理\n",
    "tweet_data = tweet_data.dropna()\n",
    "tweet_data = tweet_data[~tweet_data['tweet'].str.contains('#REF!', na=False)]\n",
    "valid_labels = ['Agree', 'Mostly Agree']\n",
    "tweet_data = tweet_data[tweet_data['5_label_majority_answer'].isin(valid_labels)]\n",
    "\n",
    "# 移除 5_label_majority_answer 欄位，並重新命名欄位\n",
    "tweet_data = tweet_data.rename(columns={'BinaryNumTarget': 'label', 'tweet': 'text'})\n",
    "tweet_data = tweet_data[['text', 'label']]\n",
    "\n",
    "tweet_data_num = 1000  # 取n筆\n",
    "tweet_data = tweet_data.groupby('label').apply(\n",
    "    lambda x: x.sample(n=min(len(x), tweet_data_num), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(tweet_data['label'].value_counts())\n",
    "print(tweet_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ab861",
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1749735938240,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "4c3ab861"
   },
   "outputs": [],
   "source": [
    "# 合併兩份不同來源資料集\n",
    "data = pd.concat([news_data, tweet_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b5ac9",
   "metadata": {
    "id": "3b7b5ac9"
   },
   "source": [
    "## 需要做文本預處理嗎?\n",
    "\n",
    "目的:\n",
    "- 建立分類器來預測真假新聞 -> (TF-IDF + 分類模型需要乾淨的資料，有幫助)\n",
    "- 分析NER 結果與語意分佈 -> (會破壞語意)\n",
    "- 建立主題模型來探索語意主題（BERTopic -> (會破壞語意)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e324aa",
   "metadata": {
    "executionInfo": {
     "elapsed": 1467,
     "status": "ok",
     "timestamp": 1749735939726,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "d5e324aa"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punct_pattern = re.compile(r\"[^a-z ]\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = punct_pattern.sub(\" \", text)\n",
    "    # 用 preserve_line=True 避開 punkt_tab\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "    tokens = [\n",
    "        lemmatizer.lemmatize(w)\n",
    "        for w in tokens\n",
    "        if w not in stop_words and len(w) > 1\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "data['tokens'] = data['text'].astype(str).apply(preprocess)\n",
    "data['clean_text'] = data['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d2b60",
   "metadata": {
    "id": "270d2b60"
   },
   "source": [
    "## 06/10 嘗試方向 ##\n",
    "\n",
    "1. 真假新聞8成資料作為訓練集\n",
    "1. 分別用真假新聞的2成做為測試集1、推特真假推文作為測試集2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ddd12",
   "metadata": {
    "id": "e68ddd12"
   },
   "source": [
    "## NER 預測新聞真假"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df51b6",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1749735939775,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "81df51b6"
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import fontManager\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontManager.addfont('./public/TaipeiSansTCBeta-Regular.ttf')\n",
    "plt.rcParams['font.sans-serif'] = ['Taipei Sans TC Beta']\n",
    "plt.rcParams['font.size'] = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29def4a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328342,
     "status": "ok",
     "timestamp": 1749736268119,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "29def4a1",
    "outputId": "0c7820aa-6dfd-44e1-be4e-230ce207a5b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "from transformers import BertTokenizerFast, AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 載入模型與 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# 建立 NER 結果列表\n",
    "ner_rows = []\n",
    "\n",
    "# 分切字串\n",
    "def split_text(text, chunk_size=512):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 針對每篇文章跑 NER（可用 tqdm 顯示進度條）\n",
    "for idx, text in tqdm(data['text'].astype(str).items()):\n",
    "    try:\n",
    "        chunks = split_text(text)\n",
    "        all_ents = []\n",
    "        for chunk in chunks:\n",
    "            all_ents.extend(ner_pipeline(chunk))  # 對每段跑 NER\n",
    "        for ent in all_ents:\n",
    "            ner_rows.append({\n",
    "                \"index\": idx,\n",
    "                \"entity\": ent['entity_group'],  # e.g., PER, LOC\n",
    "                \"word\": ent['word'],\n",
    "                \"score\": ent['score']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error at idx {idx}: {e}\")\n",
    "\n",
    "# 建立 DataFrame\n",
    "ner_df = pd.DataFrame(ner_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c0283",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1749736268179,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "875c0283",
    "outputId": "46797349-fcf9-44d0-ae61-13cfa2979d86"
   },
   "outputs": [],
   "source": [
    "ner_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf7dd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1749736268646,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "2cbf7dd1",
    "outputId": "210344d9-aaee-415d-f07d-d334f88c2125"
   },
   "outputs": [],
   "source": [
    "# 整合 label\n",
    "merged_df = ner_df.merge(data[['label']], left_on='index', right_index=True)\n",
    "\n",
    "# 聚合所有 entity 類型的出現次數\n",
    "entity_counts_all = (\n",
    "    merged_df.groupby(['index', 'entity'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # 得到每篇文章各類實體數\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 合併 label\n",
    "entity_counts_all = entity_counts_all.merge(data[['label']], left_on='index', right_index=True)\n",
    "\n",
    "# 建模欄位選擇：所有實體類別欄位（排除 index, label）\n",
    "feature_cols = [col for col in entity_counts_all.columns if col not in ['index', 'label']]\n",
    "kmeans_fit_pred_data = entity_counts_all[feature_cols]\n",
    "\n",
    "# 做 KMeans 聚類\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "entity_counts_all['cluster'] = kmeans.fit_predict(kmeans_fit_pred_data)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(kmeans_fit_pred_data)\n",
    "entity_counts_all['PC1'] = X_pca[:, 0]\n",
    "entity_counts_all['PC2'] = X_pca[:, 1]\n",
    "# 視覺化聚類結果\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=entity_counts_all,\n",
    "    x='PC1', y='PC2', hue='cluster', style='label',\n",
    "    palette='Set2', s=100\n",
    ")\n",
    "\n",
    "plt.title('NER 特徵的主成分分析 + KMeans 聚類')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ssZp0y9GbvTr",
   "metadata": {
    "id": "ssZp0y9GbvTr"
   },
   "source": [
    "使用NER特徵進行KMeans聚類，無監督學習自動分成兩群，上圖為模型前的探索性資料分析(EDA)結果，觀察結果:KMeans聚類有部分成功聚出假新聞群，橘色cluster1幾乎都是叉叉為假新聞群，綠色cluster0包含較多真新聞與部分假新聞。結論：分群重疊明顯，整體分群效果不算非常好，但初步判斷NER有區別能力，需結合更多分類方式進行多模態聚類模型評估!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6e5bf",
   "metadata": {
    "id": "74e6e5bf"
   },
   "source": [
    "#### 嘗試用 NER 提取出的'人名'、'組織'、'地名數量'作為詞彙特徵，再餵給 TF-IDF + 模型來預測這篇新聞是真/假\n",
    "\n",
    "Part1. 使用命名實體辨識(NER)的結果當作特徵，來分類真假新聞(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d807d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1749736269642,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "a8d807d7",
    "outputId": "656d47cd-a303-4e63-d0e1-d01087815c65"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# === 建立特徵（NER 例子） ===\n",
    "entity_counts = ner_df.groupby(['index', 'entity']).size().unstack(fill_value=0)\n",
    "data_with_ner = data.copy()\n",
    "data_with_ner = data_with_ner.join(entity_counts, how='left').fillna(0)\n",
    "\n",
    "X = data_with_ner[['PER', 'ORG', 'LOC']]\n",
    "y = data_with_ner['label']\n",
    "\n",
    "# === 分類器列表 ===\n",
    "classifiers = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": svm.SVC(probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# === K-fold 設定 ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 儲存平均 f1-score 結果\n",
    "results = []\n",
    "\n",
    "# === 執行交叉驗證並印出每個模型報告 ===\n",
    "for name, model in classifiers.items():\n",
    "    print(f\"\\n=== {name} 分類結果（5-fold） ===\")\n",
    "    y_true_all, y_pred_all = [], []\n",
    "    fold_f1_scores = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        clf = clone(model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "\n",
    "        fold_f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    avg_f1 = np.mean(fold_f1_scores)\n",
    "    print(classification_report(\n",
    "        y_true_all, y_pred_all,\n",
    "        target_names=[\"真新聞\", \"假新聞\"],\n",
    "        digits=2\n",
    "    ))\n",
    "\n",
    "    results.append({\n",
    "        \"classifier\": name,\n",
    "        \"f1_weighted\": avg_f1\n",
    "    })\n",
    "\n",
    "# === 比較結果表格 ===\n",
    "result_df = pd.DataFrame(results).sort_values(by=\"f1_weighted\", ascending=False).reset_index(drop=True)\n",
    "print(\"🏁 各模型比較：\")\n",
    "print(tabulate(result_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# === 找出最佳模型 ===\n",
    "best = result_df.iloc[0]\n",
    "print(f\"\\n🏆 最佳分類器為：{best['classifier']}，weighted F1 = {best['f1_weighted']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e1c16",
   "metadata": {
    "id": "7b1e1c16"
   },
   "source": [
    "### NER提取特徵預測結果尚可\n",
    "小結:\n",
    "預測真新聞:  LR      RF\n",
    "precision   0.71    0.75\n",
    "recall      0.62    0.74\n",
    "f1          0.66    0.74\n",
    "\n",
    "預測假新聞:\n",
    "precision   0.66    0.74\n",
    "recall      0.74    0.75\n",
    "f1          0.70    0.74\n",
    "\n",
    "NER 特徵對真假新聞辨識有一定程度作用，且用RandomForest的結果較優\n",
    "\n",
    "BY Chuya\n",
    "結論：特徵太少，只有三維(PER,ORG,LOC)，只提供「人名/地名/組織」的數量，資訊量太低。很多新聞或推文不一定包含這三類實體，造成大量為 0。\n",
    "\n",
    "👉 資料區辨性低，模型難以學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ff9f4",
   "metadata": {
    "id": "400ff9f4"
   },
   "source": [
    "Part2.使用情緒分析辨識真假新聞\n",
    "\n",
    "\n",
    "1. distilbert：一款基於SST-2微調的輕量級BERT模型，常用於英文產品評論或客服對話中的情緒正負分類任務。\n",
    "2. roberta-twitter：專為Twitter資料訓練的RoBERTa模型，廣泛應用於社群貼文的輿情分析與社會事件情緒偵測。\n",
    "3. bertweet：以海量推文語料訓練的BERT模型，特別適用於社群媒體上的即時情緒追蹤與用戶反應分析。\n",
    "4. nlptown：一個支援多語言、可輸出1～5星等級的情緒強度模型，常用於多語評論評等、顧客滿意度分析等任務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d64c13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 899833,
     "status": "ok",
     "timestamp": 1749737169500,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "d3d64c13",
    "outputId": "7eded0ad-c018-4758-8b68-fd6ba73ca4b7"
   },
   "outputs": [],
   "source": [
    "# ── Part 2：情緒特徵模型比較 ───────────────────────────\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "import pandas as pd, numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "sentiment_models = {\n",
    "    \"distilbert\"      : \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    \"roberta-twitter\" : \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    \"bertweet\"        : \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
    "    \"nlptown\"         : \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"LinearSVC\"    : LinearSVC(),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "def split_chunks(txt, size=512):\n",
    "    return [txt[i:i+size] for i in range(0, len(txt), size)]\n",
    "\n",
    "def senti_score(txt, pipe):\n",
    "    try:\n",
    "        res = pipe(split_chunks(txt))\n",
    "        pos = [r['score'] for r in res if 'POS' in r['label'].upper()]\n",
    "        neg = [r['score'] for r in res if 'NEG' in r['label'].upper()]\n",
    "        return (sum(pos)/len(pos)) if pos and sum(pos) > sum(neg) \\\n",
    "               else -(sum(neg)/len(neg)) if neg else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "all_results, model_mean = [], []\n",
    "\n",
    "for m_key, m_name in sentiment_models.items():\n",
    "    print(f\"\\n🔍 Sentiment Model: {m_key}\")\n",
    "    pipe = pipeline(\"sentiment-analysis\", model=m_name, truncation=True)\n",
    "    data_tmp = data.copy()\n",
    "    tqdm.pandas()\n",
    "    data_tmp['sentiment_score'] = data_tmp['text'].astype(str).progress_apply(\n",
    "        lambda t: senti_score(t, pipe)\n",
    "    )\n",
    "\n",
    "    X_senti = data_tmp[['sentiment_score']]\n",
    "    y       = data_tmp['label']\n",
    "\n",
    "    f1_collect = []\n",
    "    for clf_key, clf in classifiers.items():\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(X_senti, y, test_size=0.2, random_state=42)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_pred = clf.predict(X_te)\n",
    "        f1_val = f1_score(y_te, y_pred, average='weighted')\n",
    "        f1_collect.append(f1_val)\n",
    "        all_results.append({\"model\": m_key, \"classifier\": clf_key, \"f1\": f1_val})\n",
    "\n",
    "    model_mean.append({\"model\": m_key, \"mean_f1\": np.mean(f1_collect)})\n",
    "\n",
    "# ➜ 找平均 F1 最高的情緒模型\n",
    "model_df = pd.DataFrame(model_mean).sort_values('mean_f1', ascending=False)\n",
    "best_senti = model_df.iloc[0]['model']\n",
    "print(\"\\n📊  情緒模型平均 F1：\")\n",
    "print(tabulate(model_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "print(f\"\\n🏆 最佳情緒模型：{best_senti}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349aa9a5",
   "metadata": {
    "id": "349aa9a5"
   },
   "outputs": [],
   "source": [
    "\"\"\"# 載入情緒分析模型(微調後的BERT)\n",
    "model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 因為這個語言也是BERT = 效果仰賴'自然語言語序與上下文' = 使用data['text']即可\n",
    "\n",
    "# 切割文字 每段不超過 512 字\n",
    "def split_text(text, chunk_size=512):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 整合段落的情緒分數\n",
    "def analyze_long_text(text):\n",
    "    try:\n",
    "        chunks = split_text(text)\n",
    "        results = model(chunks)\n",
    "\n",
    "        # 統計情緒\n",
    "        pos_scores = [r['score'] for r in results if r['label'] == 'POSITIVE']\n",
    "        neg_scores = [r['score'] for r in results if r['label'] == 'NEGATIVE']\n",
    "\n",
    "        # 平均分數\n",
    "        avg_pos = sum(pos_scores) / len(pos_scores) if pos_scores else 0\n",
    "        avg_neg = sum(neg_scores) / len(neg_scores) if neg_scores else 0\n",
    "\n",
    "        # 決定總體情續\n",
    "        if avg_pos > avg_neg:\n",
    "            return pd.Series(['POSITIVE', avg_pos])\n",
    "        elif avg_neg > avg_pos:\n",
    "            return pd.Series(['NEGATIVE', avg_neg])\n",
    "        else:\n",
    "            return pd.Series(['NEUTRAL', 0.5])\n",
    "    except Exception:\n",
    "        return pd.Series(['ERROR', 0.0])\n",
    "\n",
    "# 執行分析\n",
    "tqdm.pandas()\n",
    "data[['sentiment_label', 'sentiment_score']] = data['text'].progress_apply(analyze_long_text)\n",
    "\n",
    "data.head(10)\n",
    "\n",
    "sentiment_pred_X = data[['sentiment_score']]\n",
    "sentiment_pred_y = data['label']\n",
    "\n",
    "# 分割訓練與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_pred_X, sentiment_pred_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型並訓練\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測與評估\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 預測與評估\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, rf_y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcccc87d",
   "metadata": {
    "id": "bcccc87d"
   },
   "source": [
    "### 小結: 情緒預測真假新聞表現不好\n",
    "小結:\n",
    "預測真新聞:  LR      RF\n",
    "precision   0.60    0.52\n",
    "recall      0.37    0.50\n",
    "f1          0.46    0.51\n",
    "\n",
    "預測假新聞:\n",
    "precision   0.54    0.52\n",
    "recall      0.75    0.54\n",
    "f1          0.63    0.53\n",
    "\n",
    "整體分類效果偏弱，跟丟銅板差不多\n",
    "模型偏好預測為假新聞（recall 高），但也多誤判"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hZJmy5sYfDL8",
   "metadata": {
    "id": "hZJmy5sYfDL8"
   },
   "source": [
    "採用HuggingFace的distilbert-base-uncased-finetuned-sst-2-english模型，這是一個對英文-電影評論做情緒分類(positive/negative)的預訓練模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0b838",
   "metadata": {
    "id": "55e0b838"
   },
   "source": [
    "Part3.　嘗試整合兩者(NER+情緒)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7yrPG8mXmvfH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 232013,
     "status": "ok",
     "timestamp": 1749737401520,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "7yrPG8mXmvfH",
    "outputId": "0fc62356-f179-4a19-aca2-26bef50a20a4"
   },
   "outputs": [],
   "source": [
    "# ── Part 3：NER + Best Sentiment 特徵訓練 ──────────────\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "# 1️⃣ 用最佳情緒模型重新計算 sentiment_score\n",
    "best_pipe = pipeline(\"sentiment-analysis\", model=sentiment_models[best_senti], truncation=True)\n",
    "tqdm.pandas()\n",
    "data['sentiment_score'] = data['text'].astype(str).progress_apply(lambda t: senti_score(t, best_pipe))\n",
    "\n",
    "# 2️⃣ 合併 NER (PER/ORG/LOC) + sentiment_score\n",
    "feature_df = data_with_ner[['PER', 'ORG', 'LOC']].join(data['sentiment_score'])\n",
    "X_full = feature_df\n",
    "y_full = data['label']\n",
    "\n",
    "# 3️⃣ 四個分類器\n",
    "final_clfs = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : svm.SVC(probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "final_res = []\n",
    "\n",
    "for clf_key, base_clf in final_clfs.items():\n",
    "    y_all_t, y_all_p, f1_list = [], [], []\n",
    "\n",
    "    for tr_idx, te_idx in kf.split(X_full, y_full):\n",
    "        X_tr, X_te = X_full.iloc[tr_idx], X_full.iloc[te_idx]\n",
    "        y_tr, y_te = y_full.iloc[tr_idx], y_full.iloc[te_idx]\n",
    "\n",
    "        clf = clone(base_clf)\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        y_pr = clf.predict(X_te)\n",
    "\n",
    "        y_all_t.extend(y_te); y_all_p.extend(y_pr)\n",
    "        f1_list.append(f1_score(y_te, y_pr, average='weighted'))\n",
    "\n",
    "    print(f\"\\n=== {clf_key} 整體報告 ===\")\n",
    "    print(classification_report(y_all_t, y_all_p, target_names=[\"真新聞\",\"假新聞\"], digits=2))\n",
    "\n",
    "    final_res.append({\"classifier\": clf_key, \"f1_weighted\": np.mean(f1_list)})\n",
    "\n",
    "# 4️⃣ 比較表 & 最佳分類器\n",
    "final_df = pd.DataFrame(final_res).sort_values('f1_weighted', ascending=False).reset_index(drop=True)\n",
    "print(\"\\n📊  最終 4 分類器比較：\")\n",
    "print(tabulate(final_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best_cls = final_df.iloc[0]\n",
    "print(f\"\\n🏆 最終最佳組合：情緒模型={best_senti} + 分類器={best_cls['classifier']}，weighted F1={best_cls['f1_weighted']:.4f}\")\n",
    "\n",
    "# 5️⃣ (可選) 視覺化\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=final_df, palette='Set2')\n",
    "plt.title(f'NER + Sentiment({best_senti})  4 分類器比較')\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec497be",
   "metadata": {
    "id": "eec497be"
   },
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "combined_X = pd.concat([data_with_ner[['PER', 'ORG', 'LOC']], sentiment_pred_X], axis=1)\n",
    "combined_y = data['label']\n",
    "# 分割訓練與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "lr_preds = clf_lr.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_preds = clf_rf.predict(X_test)\n",
    "\n",
    "# 評估結果\n",
    "print(\"=== Logistic Regression 分類結果 ===\")\n",
    "print(classification_report(y_test, lr_preds))\n",
    "\n",
    "print(\"=== Random Forest 分類結果 ===\")\n",
    "print(classification_report(y_test, rf_preds)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2OZ3X91gvzZA",
   "metadata": {
    "id": "2OZ3X91gvzZA"
   },
   "source": [
    "Part4.NER+情緒+TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8U7BNkkiv8yI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 230421,
     "status": "ok",
     "timestamp": 1749737631960,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "8U7BNkkiv8yI",
    "outputId": "d121b30c-9bcd-4cbb-b5d0-72ea0d4f5d6e"
   },
   "outputs": [],
   "source": [
    "# ── Part 4：TF-IDF + NER + Best Sentiment 模型 ──────────────────────\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from tabulate import tabulate\n",
    "from transformers import pipeline\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ 使用 Part 2 最佳情緒模型重新生成 sentiment_score\n",
    "senti_model_name = sentiment_models[best_senti]\n",
    "sentiment_pipe = pipeline(\"sentiment-analysis\", model=senti_model_name, truncation=True)\n",
    "tqdm.pandas()\n",
    "data['sentiment_score'] = data['text'].astype(str).progress_apply(lambda t: senti_score(t, sentiment_pipe))\n",
    "\n",
    "# 1️⃣ 建立 TF-IDF 特徵\n",
    "tfidf_vec = TfidfVectorizer(max_features=200, ngram_range=(1, 2))\n",
    "tfidf_mat = tfidf_vec.fit_transform(data['clean_text'].fillna(''))\n",
    "tfidf_df = pd.DataFrame(tfidf_mat.toarray(),\n",
    "                        columns=tfidf_vec.get_feature_names_out(),\n",
    "                        index=data.index)\n",
    "\n",
    "# 2️⃣ 取得 NER 特徵 + 最新 sentiment 分數\n",
    "ner_df     = data_with_ner[['PER', 'ORG', 'LOC']].copy()\n",
    "senti_df   = data[['sentiment_score']]\n",
    "X_features = pd.concat([ner_df, senti_df, tfidf_df], axis=1)\n",
    "y_target   = data['label']\n",
    "\n",
    "# 3️⃣ 定義分類器\n",
    "classifiers = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : svm.SVC(probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# 4️⃣ Cross-Validation 訓練\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for clf_name, clf_model in classifiers.items():\n",
    "    print(f\"\\n=== {clf_name} 分類結果（5-fold） ===\")\n",
    "    y_all_true, y_all_pred, f1s = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X_features, y_target):\n",
    "        X_train, X_test = X_features.iloc[train_idx], X_features.iloc[test_idx]\n",
    "        y_train, y_test = y_target.iloc[train_idx], y_target.iloc[test_idx]\n",
    "\n",
    "        clf = clone(clf_model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        y_all_true.extend(y_test)\n",
    "        y_all_pred.extend(y_pred)\n",
    "        f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    print(classification_report(y_all_true, y_all_pred,\n",
    "                                target_names=[\"真新聞\", \"假新聞\"], digits=2))\n",
    "\n",
    "    results.append({\n",
    "        \"classifier\": clf_name,\n",
    "        \"f1_weighted\": np.mean(f1s)\n",
    "    })\n",
    "\n",
    "# 5️⃣ 輸出總結\n",
    "result_df = pd.DataFrame(results).sort_values(by='f1_weighted', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n📊 TF-IDF + NER + Sentiment 分類器比較：\")\n",
    "print(tabulate(result_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best = result_df.iloc[0]\n",
    "print(f\"\\n🏆 最佳分類器為：{best['classifier']}，weighted F1 = {best['f1_weighted']:.4f}\")\n",
    "\n",
    "# ➕ 可選視覺化\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=result_df, palette='Set3')\n",
    "plt.title(f\"TF-IDF + NER + Sentiment({best_senti}) 分類器比較\")\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3xHOBUT211bp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1749737632097,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "3xHOBUT211bp",
    "outputId": "f0ab62f9-a352-44a7-de19-5e04ffaa6af8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 依 label 分群\n",
    "true_texts = data[data['label'] == 0]['clean_text'].fillna('')\n",
    "fake_texts = data[data['label'] == 1]['clean_text'].fillna('')\n",
    "\n",
    "# 建立 TF-IDF 向量器（可使用相同設定以便比較）\n",
    "tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "\n",
    "# 擬合於真新聞\n",
    "true_tfidf_matrix = tfidf.fit_transform(true_texts)\n",
    "true_feature_names = tfidf.get_feature_names_out()\n",
    "true_scores = true_tfidf_matrix.mean(axis=0).A1\n",
    "true_top30 = sorted(zip(true_feature_names, true_scores), key=lambda x: x[1], reverse=True)[:30]\n",
    "\n",
    "# 擬合於假新聞（需重新建一個 vectorizer 才不會共用字典）\n",
    "tfidf_fake = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "fake_tfidf_matrix = tfidf_fake.fit_transform(fake_texts)\n",
    "fake_feature_names = tfidf_fake.get_feature_names_out()\n",
    "fake_scores = fake_tfidf_matrix.mean(axis=0).A1\n",
    "fake_top30 = sorted(zip(fake_feature_names, fake_scores), key=lambda x: x[1], reverse=True)[:30]\n",
    "\n",
    "# 將兩個 DataFrame 加上 index 並 reset\n",
    "true_df = pd.DataFrame(true_top30, columns=[\"真新聞詞\", \"真_TF-IDF\"]).reset_index(drop=True)\n",
    "fake_df = pd.DataFrame(fake_top30, columns=[\"假新聞詞\", \"假_TF-IDF\"]).reset_index(drop=True)\n",
    "\n",
    "# 合併為一個表格（左右比對）\n",
    "compare_df = pd.concat([true_df, fake_df], axis=1)\n",
    "\n",
    "# 顯示結果\n",
    "from IPython.display import display\n",
    "print(\"📊 真新聞 vs 假新聞 前 30 常見關鍵詞（TF-IDF 分數）\")\n",
    "display(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6497f1",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8d6497f1",
    "outputId": "3ba8250f-f1b6-41fc-b790-8d53a8a04ec9"
   },
   "outputs": [],
   "source": [
    "# \"\"\"# 嘗試增加TF-IDF欄位(clean_text)\n",
    "\n",
    "# # 建立 TF-IDF 向量器（可自訂 ngram 範圍與維度限制）\n",
    "# tfidf = TfidfVectorizer(max_features=200, ngram_range=(1, 2))\n",
    "# tfidf_matrix = tfidf.fit_transform(data['clean_text'].fillna(''))\n",
    "\n",
    "# # 轉為 DataFrame\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out(), index=data.index)\n",
    "\n",
    "# # 新增tf-idf欄位\n",
    "# ner_sentiment_df = pd.concat([ner_pred_X, sentiment_pred_X], axis=1)\n",
    "# combined_X_full = pd.concat([ner_sentiment_df, tfidf_df], axis=1)\n",
    "\n",
    "# # 分割資料\n",
    "# X_train, X_test, y_train, y_test = train_test_split(combined_X_full, combined_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Logistic\n",
    "# clf_lr = LogisticRegression()\n",
    "# clf_lr.fit(X_train, y_train)\n",
    "# lr_preds = clf_lr.predict(X_test)\n",
    "\n",
    "# # Random Forest\n",
    "# clf_rf = RandomForestClassifier(random_state=42)\n",
    "# clf_rf.fit(X_train, y_train)\n",
    "# rf_preds = clf_rf.predict(X_test)\n",
    "\n",
    "# # 評估\n",
    "# print(\"=== Logistic Regression(NER + Sentiment + TF-IDF) ===\")\n",
    "# print(classification_report(y_test, lr_preds))\n",
    "\n",
    "# print(\"=== Random Forest(NER + Sentiment + TF-IDF) ===\")\n",
    "# print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S1F-x4xHLhyi",
   "metadata": {
    "id": "S1F-x4xHLhyi"
   },
   "source": [
    "Part5. TF-IDF+NER+Sentiment特徵上，再加入VADER(+Empath)與文字表達Style特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3iJgV5_gMNHs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10054,
     "status": "ok",
     "timestamp": 1749733273778,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "3iJgV5_gMNHs",
    "outputId": "f2697dd2-9025-40f6-f2c3-bd07a5a8966f"
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment empath tabulate tqdm seaborn matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFDPH3NGLf7k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5075,
     "status": "ok",
     "timestamp": 1749737722134,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "SFDPH3NGLf7k",
    "outputId": "ebc5fc07-1527-4bcd-ea51-d8ca1ad15c32"
   },
   "outputs": [],
   "source": [
    "# ── Part 5：TF-IDF+NER+Sentiment特徵上，再加入VADER(+Empath)與文字表達Style特徵 ──────────────────────\n",
    "# ------------------------------------------------------------------\n",
    "# 1. 透過卡方檢定 (chi-square) 找出「假新聞 > 真新聞」最具區辨力的 n-gram\n",
    "# ------------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np, pandas as pd, re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# （1）建一個詞袋模型（unigram+bigram，過濾英文停用字, min_df=5 避免太稀有）\n",
    "cv = CountVectorizer(stop_words='english', ngram_range=(1,2), min_df=5)\n",
    "X_bow = cv.fit_transform(data['clean_text'])\n",
    "feature_names = np.array(cv.get_feature_names_out())\n",
    "\n",
    "# （2）做卡方檢定；label=1 代表假新聞\n",
    "chi_scores, _ = chi2(X_bow, data['label'])\n",
    "\n",
    "# （3）只保留在假新聞出現次數 > 真新聞的詞，再取前 30 名\n",
    "fake_mask = (X_bow[data['label'].values==1].sum(axis=0) >\n",
    "             X_bow[data['label'].values==0].sum(axis=0)).A1\n",
    "candidate_words = feature_names[fake_mask]\n",
    "candidate_scores= chi_scores[fake_mask]\n",
    "\n",
    "top_k = 30\n",
    "top_idx = np.argsort(candidate_scores)[::-1][:top_k]\n",
    "auto_clickbait = set(candidate_words[top_idx])\n",
    "\n",
    "print(f\"🔍 自動偵測到 {len(auto_clickbait)} 個假新聞高相關詞（前 {top_k}）：\")\n",
    "print(sorted(auto_clickbait))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. 建立 VADER / Empath / Style 特徵（含「動態 click-bait」）\n",
    "# ------------------------------------------------------------------\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "try:\n",
    "    from empath import Empath\n",
    "    lexicon = Empath(); use_empath = True\n",
    "except ModuleNotFoundError:\n",
    "    use_empath = False\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# 2-1 VADER\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "vader_df = (data['text'].progress_apply(vader.polarity_scores)\n",
    "                       .apply(pd.Series).add_prefix('vader_'))\n",
    "print(\"\\n🧠 VADER 情緒推動特徵（前幾筆）：\")\n",
    "print(vader_df.head())\n",
    "\n",
    "# 2-2 Empath（選擇幾個常用情緒社會面向）\n",
    "if use_empath:\n",
    "    empath_raw = data['text'].progress_apply(lambda t: lexicon.analyze(t, normalize=True))\n",
    "    empath_keep = ['positive_emotion','negative_emotion','anger','sadness',\n",
    "                   'fear','politics','money','fun','love']\n",
    "    empath_df = (pd.DataFrame(empath_raw.tolist())\n",
    "                   [empath_keep].add_prefix('empath_'))\n",
    "\n",
    "    print(\"\\n🎯 NRC-Empath 情緒向量（前幾筆）：\")\n",
    "    print(empath_df.head())\n",
    "else:\n",
    "    empath_df = pd.DataFrame(index=data.index)   # 空 DF\n",
    "    print(\"\\n⚠️ 未啟用 Empath（需 pip install empath）\")\n",
    "\n",
    "# 2-3 Style features（大寫比例 / ! 密度 / 自動 click-bait 命中率）\n",
    "def style_feats(txt:str):\n",
    "    L = max(len(txt),1)\n",
    "    txt_low = txt.lower()\n",
    "    hit_cnt = sum(1 for w in auto_clickbait if w in txt_low)\n",
    "    return pd.Series({\n",
    "        'caps_ratio'      : sum(c.isupper() for c in txt)/L,\n",
    "        'excl_ratio'      : txt.count('!')/L,\n",
    "        'clickbait_ratio' : hit_cnt / len(auto_clickbait)\n",
    "    })\n",
    "\n",
    "style_df = data['text'].progress_apply(style_feats)\n",
    "\n",
    "print(\"\\n📝 文字表達方式特徵（大寫比例 / 感嘆號密度 / Click-bait 命中率）\")\n",
    "print(style_df.describe())\n",
    "\n",
    "print(\"\\n📊 假新聞與真新聞的 Style 特徵平均比較：\")\n",
    "print(pd.concat([style_df, data['label']], axis=1)\n",
    "        .groupby('label').mean()\n",
    "        .rename(index={0: \"真新聞\", 1: \"假新聞\"}))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. 把新特徵接到既有 X_features（TF-IDF + NER + Best-Sentiment）\n",
    "# ------------------------------------------------------------------\n",
    "X_final = pd.concat([X_features, vader_df, empath_df, style_df], axis=1)\n",
    "y_final = data['label']\n",
    "print(\"🔢 新增後特徵維度 :\", X_final.shape)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. 四個分類器 × 5-fold 交叉驗證\n",
    "# ------------------------------------------------------------------\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "\n",
    "clfs = {\n",
    "    \"LogReg\"      : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"SVM\"         : SVC(probability=True),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "rows = []\n",
    "\n",
    "for name, base in clfs.items():\n",
    "    y_t, y_p, f1s = [], [], []\n",
    "    for tr, te in kf.split(X_final, y_final):\n",
    "        mdl = clone(base).fit(X_final.iloc[tr], y_final.iloc[tr])\n",
    "        pred = mdl.predict(X_final.iloc[te])\n",
    "        y_t.extend(y_final.iloc[te]); y_p.extend(pred)\n",
    "        f1s.append(f1_score(y_final.iloc[te], pred, average='weighted'))\n",
    "    print(f\"\\n=== {name} 報告 (加 VADER / Style) ===\")\n",
    "    print(classification_report(y_t, y_p, target_names=['真新聞','假新聞'], digits=2))\n",
    "    rows.append({\"classifier\": name, \"f1_weighted\": np.mean(f1s)})\n",
    "\n",
    "res_df = pd.DataFrame(rows).sort_values('f1_weighted', ascending=False)\n",
    "print(\"\\n📊  加 VADER / Style / 動態 Click-bait 後分類器比較\")\n",
    "print(tabulate(res_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best_cls = res_df.iloc[0]\n",
    "print(f\"\\n🏆  新最佳模型：{best_cls['classifier']}  (Weighted F1 = {best_cls['f1_weighted']:.4f})\")\n",
    "\n",
    "# （可選）長條圖\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=res_df, palette='Set2')\n",
    "plt.title('加入 VADER / Style 特徵後的分類器比較')\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0,1); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kXCGLyxag7DL",
   "metadata": {
    "id": "kXCGLyxag7DL"
   },
   "source": [
    "Part6. NER+Sentiment特徵+SBERT向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RRiE1c9WgFLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1bd81346eb5446ae86c8992ea87a8979",
      "3aa0234db1f4447da06ae0ba78593276",
      "aaefd6793ed644b3afbf183bec859bff",
      "e108b8551f0e41b69ce386e7cbdf3945",
      "9c0fc22fc33a4388b5cde67492782329",
      "a7bd128141e746019bbd9eeed16eda0c",
      "c9da9c06c90a475ab7e45abc95f3dec3",
      "953dd787d72045bc9382fef65869ced1",
      "30cfa6df7235440a8aaf12b38e7c1a24",
      "2ff3e28618eb412c9f1879564137be6c",
      "07b0a05b872c48ec8bc00ec063304866"
     ]
    },
    "executionInfo": {
     "elapsed": 13099,
     "status": "ok",
     "timestamp": 1749738724842,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "RRiE1c9WgFLd",
    "outputId": "3b0c94d7-cadd-4537-9858-96bf4b02f141"
   },
   "outputs": [],
   "source": [
    "# ────── Part 6：NER+Sentiment特徵+SBERT向量化 ──────────────────────\n",
    "# ▍1. SBERT 向量化\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-MiniLM-L6-v2')  # 可改其他如 'paraphrase-MiniLM-L6-v2'\n",
    "sbert_embeddings = model.encode(data['clean_text'].fillna(''), show_progress_bar=True)\n",
    "\n",
    "sbert_df = pd.DataFrame(sbert_embeddings, index=data.index)\n",
    "sbert_df.columns = sbert_df.columns.astype(str)\n",
    "print(\"📐 向量維度：\", sbert_df.shape)\n",
    "\n",
    "# ▍2. 合併其他特徵（NER + Sentiment）\n",
    "ner_df    = data_with_ner[['PER', 'ORG', 'LOC']].copy()\n",
    "senti_df  = data[['sentiment_score']]\n",
    "X_sbert   = pd.concat([sbert_df, ner_df, senti_df], axis=1)\n",
    "y_target  = data['label']\n",
    "\n",
    "# ▍3. 建立分類器組合\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.base import clone\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "classifiers = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : SVC(probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# ▍4. Cross-validation 比較表現\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for clf_name, clf_model in classifiers.items():\n",
    "    print(f\"\\n=== {clf_name} 分類結果（5-fold） ===\")\n",
    "    y_all_true, y_all_pred, f1s = [], [], []\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X_sbert, y_target):\n",
    "        X_train, X_test = X_sbert.iloc[train_idx], X_sbert.iloc[test_idx]\n",
    "        y_train, y_test = y_target.iloc[train_idx], y_target.iloc[test_idx]\n",
    "\n",
    "        clf = clone(clf_model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        y_all_true.extend(y_test)\n",
    "        y_all_pred.extend(y_pred)\n",
    "        f1s.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    print(classification_report(y_all_true, y_all_pred, target_names=[\"真新聞\", \"假新聞\"], digits=2))\n",
    "\n",
    "    results.append({\n",
    "        \"classifier\": clf_name,\n",
    "        \"f1_weighted\": np.mean(f1s)\n",
    "    })\n",
    "\n",
    "# ▍5. 顯示比較結果\n",
    "result_df = pd.DataFrame(results).sort_values(by='f1_weighted', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n📊 SBERT + NER + Sentiment 分類器比較：\")\n",
    "print(tabulate(result_df, headers=\"keys\", tablefmt=\"fancy_grid\"))\n",
    "\n",
    "best = result_df.iloc[0]\n",
    "print(f\"\\n🏆 最佳分類器為：{best['classifier']}，weighted F1 = {best['f1_weighted']:.4f}\")\n",
    "\n",
    "# ▍6. 視覺化結果\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x='classifier', y='f1_weighted', data=result_df, palette='Set2')\n",
    "plt.title(\"BERT 向量 + NER + Sentiment 分類器比較\")\n",
    "plt.ylabel('Weighted F1')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HbkktXE-jqDV",
   "metadata": {
    "id": "HbkktXE-jqDV"
   },
   "source": [
    "1. 使用all-MiniLM-L6-v2，最佳分類器為：RandomForest，weighted F1 = 0.7197\n",
    "2. 使用sentence-transformers/paraphrase-MiniLM-L6-v2，最佳分類器為：LogReg，weighted F1 = 0.7467"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa66961",
   "metadata": {
    "id": "2aa66961"
   },
   "source": [
    "### Topic model: BERTopic 主題詞來源使用c-TF-IDF頻率導向，挑出詞頻高的詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gmCYJY1vm9EW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1611,
     "status": "ok",
     "timestamp": 1749741036530,
     "user": {
      "displayName": "Etta Chuang",
      "userId": "11710828896069713513"
     },
     "user_tz": -480
    },
    "id": "gmCYJY1vm9EW",
    "outputId": "5b1a8b04-f301-4c61-8191-b9a0d51b4ed1"
   },
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "# 0. 前置條件說明\n",
    "#   - data['clean_text'] 需為清理後文本欄\n",
    "#   - data['label'] 為真假標記（0=真新聞，1=假新聞）\n",
    "#   - 若用 \"tfidf_style\"，需已先算好 X_final\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------- 1. 選擇向量化方式 -------------------------------------Part 4 / 5 / 6 結果輸入\n",
    "VEC_CHOICE = \"tfidf\"       # ← 輸入 # Part 4- \"tfidf\" / Part 5- \"tfidf_style\" / Part 6- \"sbert\"\n",
    "texts = data['clean_text'].fillna('')\n",
    "\n",
    "if VEC_CHOICE == \"tfidf\":\n",
    "    vec_model = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=\"english\")\n",
    "    embeddings = vec_model.fit_transform(texts)\n",
    "\n",
    "elif VEC_CHOICE == \"tfidf_style\":\n",
    "    if \"X_final\" not in globals():\n",
    "        raise RuntimeError(\"⚠️ 找不到 X_final，請先執行 Part 5 建立特徵\")\n",
    "    embeddings = X_final.values\n",
    "\n",
    "elif VEC_CHOICE == \"sbert\":\n",
    "    emb_model = SentenceTransformer(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "    embeddings = emb_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"VEC_CHOICE 僅能為 'tfidf' / 'tfidf_style' / 'sbert'\")\n",
    "\n",
    "# -------- 2. 建立 BERTopic 模型 ----------------------------------\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=None if VEC_CHOICE.startswith(\"tfidf\") else emb_model,\n",
    "    hdbscan_model=HDBSCAN(min_cluster_size=10, min_samples=30),\n",
    "    vectorizer_model=CountVectorizer(ngram_range=(1, 2), stop_words=\"english\"),\n",
    "    calculate_probabilities=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "topics, _ = topic_model.fit_transform(texts, embeddings)\n",
    "data['topic'] = topics\n",
    "\n",
    "# ✅ 防呆：確認是否有有效主題（非 -1）\n",
    "valid_topics = [t for t in set(topics) if t != -1]\n",
    "if len(valid_topics) == 0:\n",
    "    print(\"⚠️ 無有效主題（全部為 outlier），請檢查資料筆數或降低 min_cluster_size 設定。\")\n",
    "else:\n",
    "    # -------- 3. 主題 × 真／假 分佈 -------------------------------\n",
    "    data['label_name'] = data['label'].map({0: \"True\", 1: \"Fake\"})\n",
    "    topic_dist = (data.groupby(['topic', 'label_name']).size().unstack(fill_value=0))\n",
    "    topic_dist['Total'] = topic_dist.sum(axis=1)\n",
    "    topic_dist['Fake_Ratio'] = topic_dist['Fake'] / topic_dist['Total']\n",
    "\n",
    "    print(\"▶ 各 Topic 真／假筆數與假新聞比例 (前 10)：\")\n",
    "    display(topic_dist.sort_values('Fake_Ratio', ascending=False).head(10))\n",
    "\n",
    "    # -------- 4. 取主題關鍵字並依真假比例排序 ----------------------\n",
    "    kw_rows = []\n",
    "    for tid, word_scores in topic_model.get_topics().items():\n",
    "        if tid == -1:\n",
    "            continue\n",
    "        for word, score in word_scores:\n",
    "            kw_rows.append({\"topic\": tid, \"word\": word, \"c_tf_idf\": score})\n",
    "\n",
    "    kw_df = pd.DataFrame(kw_rows)\n",
    "\n",
    "    merged_kw = kw_df.merge(topic_dist.reset_index(), on=\"topic\")\n",
    "\n",
    "    fake_top_kw = (merged_kw.sort_values(['Fake_Ratio', 'c_tf_idf'], ascending=[False, False])\n",
    "                            .groupby('topic')\n",
    "                            .head(30))\n",
    "\n",
    "    true_top_kw = (merged_kw.sort_values(['Fake_Ratio', 'c_tf_idf'], ascending=[True, False])\n",
    "                            .groupby('topic')\n",
    "                            .head(30))\n",
    "\n",
    "    print(\"\\n🟥 假新聞高比例主題關鍵字 TOP 30\")\n",
    "    display(fake_top_kw[['topic', 'word', 'c_tf_idf', 'Fake_Ratio']])\n",
    "\n",
    "    print(\"\\n🟦 真新聞高比例主題關鍵字 TOP 30\")\n",
    "    display(true_top_kw[['topic', 'word', 'c_tf_idf', 'Fake_Ratio']])\n",
    "\n",
    "    # -------- 5. 視覺化每個主題的假新聞比例 ------------------------\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    sns.barplot(x=topic_dist.index, y=topic_dist['Fake_Ratio'], palette=\"coolwarm\")\n",
    "    plt.title(\"Fake-News Ratio per Topic\")\n",
    "    plt.ylabel(\"Fake Ratio\")\n",
    "    plt.xlabel(\"Topic ID\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "osakI7pZsZuG",
   "metadata": {
    "id": "osakI7pZsZuG"
   },
   "source": [
    "「先用最佳向量化(SBERT)→BERTopic分群→疊加真假標籤→看每個主題哪邊假新聞高、哪邊真新聞高，以及對應關鍵詞的全流程。\n",
    "\n",
    "將兩者疊加，就能得到：\n",
    "「假新聞最常見的主題有哪些？」/「真新聞裡哪些主題特別突出？」/「各主題的代表關鍵詞」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be7f71",
   "metadata": {
    "id": "19be7f71"
   },
   "outputs": [],
   "source": [
    "# '''from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # 真假新聞進行主題建模\n",
    "# docs = data['text'].astype(str).tolist()\n",
    "\n",
    "# # 模型可換成 'all-MiniLM-L6-v2', 'microsoft/Phi-4-mini-instruct' 等\n",
    "# embedding_model = 'all-MiniLM-L6-v2'\n",
    "\n",
    "# # 可調整 測試用2000筆\n",
    "# # min_cluster_size 群集最少需要包含n個點，否則會被視為雜訊（noise）\n",
    "# # min_samples 包含至少n篇文章的主題才會被承認為主題\n",
    "# hdbscan_model = HDBSCAN(min_cluster_size=10, min_samples=30) # Clustering layer\n",
    "# vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "\n",
    "# topic_model = BERTopic(embedding_model=embedding_model, hdbscan_model=hdbscan_model, vectorizer_model=vectorizer_model)\n",
    "# topics, probs = topic_model.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3442db2",
   "metadata": {
    "id": "c3442db2"
   },
   "outputs": [],
   "source": [
    "# '''# 建立一個儲存所有主題關鍵詞與 TF-IDF 分數的清單\n",
    "# all_topics = []\n",
    "\n",
    "# # 把主題總數拿出來（排除 -1 是未分類主題）\n",
    "# valid_topics = [topic for topic in topic_model.get_topic_info().Topic if topic != -1]\n",
    "\n",
    "# # 對每個主題取得詞與 c-TF-IDF 分數\n",
    "# for topic_id in valid_topics:\n",
    "#     topic_words = topic_model.get_topic(topic_id)\n",
    "#     for word, score in topic_words:\n",
    "#         all_topics.append({\n",
    "#             \"Topic\": topic_id,\n",
    "#             \"Word\": word,\n",
    "#             \"C-TF-IDF\": score\n",
    "#         })\n",
    "\n",
    "# # 轉換成 DataFrame 並排序\n",
    "# topic_tfidf_df = pd.DataFrame(all_topics)\n",
    "# topic_tfidf_df = topic_tfidf_df.sort_values(by=[\"Topic\", \"C-TF-IDF\"], ascending=[True, False])\n",
    "\n",
    "# # 顯示前幾列\n",
    "# topic_tfidf_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf36076",
   "metadata": {
    "id": "aaf36076"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # 列出文章的BERTopic資訊\n",
    "# topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088184f",
   "metadata": {
    "id": "4088184f"
   },
   "outputs": [],
   "source": [
    "# def visualize_fake_news_ratio_by_topic(model, docs, labels, title=\"主題的假新聞比例\"):\n",
    "#     doc_info = model.get_document_info(docs).copy()\n",
    "#     doc_info['label'] = labels\n",
    "\n",
    "#     # 計算比例與數量\n",
    "#     topic_fake_ratio = (\n",
    "#         doc_info[doc_info['Topic'] != -1]\n",
    "#         .groupby('Topic')['label']\n",
    "#         .mean()\n",
    "#         .reset_index()\n",
    "#         .rename(columns={'label': 'fake_news_ratio'})\n",
    "#     )\n",
    "#     topic_counts = (\n",
    "#         doc_info[doc_info['Topic'] != -1]['Topic']\n",
    "#         .value_counts()\n",
    "#         .rename_axis('Topic')\n",
    "#         .reset_index(name='count')\n",
    "#     )\n",
    "#     topic_stats = pd.merge(topic_fake_ratio, topic_counts, on='Topic')\n",
    "\n",
    "#     # 加上主題名稱\n",
    "#     topic_names = model.get_topic_info()[['Topic', 'Name']]\n",
    "#     topic_stats_named = topic_stats.merge(topic_names, on='Topic')\n",
    "\n",
    "#     # 過濾比例過低的主題\n",
    "#     topic_stats_named = topic_stats_named[topic_stats_named['fake_news_ratio'] >= 0.1]\n",
    "\n",
    "#     # 繪圖\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     ax = sns.barplot(\n",
    "#         data=topic_stats_named.sort_values(by='fake_news_ratio', ascending=False),\n",
    "#         x='fake_news_ratio', y='Name', palette='Reds'\n",
    "#     )\n",
    "#     plt.title(title)\n",
    "#     plt.xlabel('假新聞比例 (label=1)')\n",
    "#     plt.ylabel('主題代表詞')\n",
    "#     plt.grid(True, axis='x')\n",
    "#     ax.set_yticklabels(ax.get_yticklabels(), fontsize=9)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d4a85",
   "metadata": {
    "id": "b55d4a85"
   },
   "source": [
    "### representation topic model: 加上語意導向的KeyBERT, 表現方式是語意向量相似的詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f408c",
   "metadata": {
    "id": "281f408c"
   },
   "outputs": [],
   "source": [
    "# from bertopic.representation import KeyBERTInspired\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# embedding_model_with_st = SentenceTransformer(embedding_model)  # 或其他你指定的模型\n",
    "# embeddings = embedding_model_with_st.encode(docs, show_progress_bar=True)\n",
    "\n",
    "# # 關鍵詞表示模型（非生成式）\n",
    "# keybert = KeyBERTInspired()\n",
    "\n",
    "# # 組裝 representation model\n",
    "# representation_model = {\n",
    "#     \"KeyBERT\": keybert\n",
    "# }\n",
    "\n",
    "# # 建立 BERTopic 模型（用 KeyBERT 調整主題表示）\n",
    "# representation_topic_model = BERTopic(\n",
    "#     embedding_model=embedding_model_with_st,\n",
    "#     vectorizer_model=vectorizer_model,\n",
    "#     hdbscan_model=hdbscan_model,\n",
    "#     representation_model=representation_model,\n",
    "#     top_n_words=30,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# # 訓練模型\n",
    "# topics, probs = representation_topic_model.fit_transform(docs, embeddings)\n",
    "\n",
    "# # 查看新的主題表示\n",
    "# representation_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f35ca8",
   "metadata": {
    "id": "f5f35ca8"
   },
   "outputs": [],
   "source": [
    "# # 視覺化主題分布：圓圈大小是主題的大小，圓圈的距離是主題之間的相似度\n",
    "# topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52eb8b",
   "metadata": {
    "id": "4c52eb8b"
   },
   "outputs": [],
   "source": [
    "# representation_topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5782e",
   "metadata": {
    "id": "9de5782e"
   },
   "outputs": [],
   "source": [
    "# # 原始模型的主題\n",
    "# visualize_fake_news_ratio_by_topic(topic_model, docs, data['label'], title=\"原始主題的假新聞比例\")\n",
    "\n",
    "# # 使用 KeyBERT 表示詞的模型主題\n",
    "# visualize_fake_news_ratio_by_topic(representation_topic_model, docs, data['label'], title=\"KeyBERT 主題的假新聞比例\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5762b28",
   "metadata": {},
   "source": [
    "## LLM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama  # 使用 Ollama 封裝的 LLaMA 模型\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 定義輸出結構\n",
    "class MessageClassification(BaseModel):\n",
    "    verdict: str = Field(description=\"Verdict whether the message is Real or Fake\")\n",
    "    confidence: str = Field(description=\"Confidence level of the judgment (e.g., High, Medium, Low)\")\n",
    "    reason: str = Field(description=\"Brief explanation of the judgment\")\n",
    "\n",
    "# 使用本地 LLaMA 模型\n",
    "judge_llm = ChatOllama(model=\"llama3:8B\")\n",
    "logic_llm = ChatOllama(model=\"phi3:3.8B\")\n",
    "debater_llm = ChatOllama(model=\"mistral:7B\")\n",
    "\n",
    "# Json 輸出格式解析器\n",
    "parser = JsonOutputParser(pydantic_object=MessageClassification)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# 單一 LLM 推理的 Prompt\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a professional fact-checker. Analyze the following message and determine if it is real or fake.\n",
    "\n",
    "Message:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\n",
    "Fill in this exact JSON format (no extra text!):\n",
    "\n",
    "{{\n",
    "  \"verdict\": \"\",        // \"Real\" or \"Fake\"\n",
    "  \"confidence\": \"\",     // \"High\", \"Medium\", or \"Low\"\n",
    "  \"reason\": \"\"          // Short explanation (1-2 sentences)\n",
    "}}\n",
    "\n",
    "Remember:\n",
    "- DO NOT add anything outside the JSON.\n",
    "- DO NOT wrap it in markdown (e.g., ```json).\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 讓 judge_llm 匯總所有模型觀點的 Prompt\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are the final arbiter. Three experts have evaluated the message. Please summarize their opinions and give your final decision.\n",
    "\n",
    "Message:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\n",
    "Expert 1 (Logic-focused model):\n",
    "{logic_opinion}\n",
    "\n",
    "Expert 2 (Debate-focused model):\n",
    "{debate_opinion}\n",
    "\n",
    "Expert 3 (Your own opinion):\n",
    "{your_opinion}\n",
    "\n",
    "Now summarize the opinions, resolve any conflicts, and provide a final classification in this JSON format:\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a57b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(text: str) -> dict:\n",
    "    try:\n",
    "        \n",
    "        # 找出第一組結構為 { ... } 的JSON區塊\n",
    "        match = re.search(r'{[\\s\\S]*?}', text)\n",
    "        if not match:\n",
    "            raise ValueError(\"No valid JSON object found in output.\")\n",
    "        json_str = match.group()\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"\\n JSON 解析失敗：{e}\")\n",
    "        print(\"原始輸出：\", text)\n",
    "        return {\n",
    "            \"verdict\": \"Unknown\",\n",
    "            \"confidence\": \"Low\",\n",
    "            \"reason\": \"Model did not return valid JSON.\"\n",
    "        }\n",
    "\n",
    "def call_llm(llm, prompt):\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if hasattr(response, \"content\") else response\n",
    "\n",
    "# 定義分析函式\n",
    "def analyze_message_with_multi_llm(message: str):\n",
    "    logic_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "    debate_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "    judge_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {\n",
    "            executor.submit(call_llm, logic_llm, logic_input): \"logic\",\n",
    "            executor.submit(call_llm, debater_llm, debate_input): \"debate\",\n",
    "            executor.submit(call_llm, judge_llm, judge_input): \"judge\"\n",
    "        }\n",
    "        results = {}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            key = futures[future]\n",
    "            results[key] = future.result()\n",
    "\n",
    "    summary_input = summary_prompt.format(\n",
    "        message=message,\n",
    "        logic_opinion=results[\"logic\"],\n",
    "        debate_opinion=results[\"debate\"],\n",
    "        your_opinion=results[\"judge\"],\n",
    "        format_instructions=format_instructions\n",
    "    )\n",
    "\n",
    "    final_response = judge_llm.invoke(summary_input)\n",
    "    result = extract_json(final_response.content)\n",
    "    return result\n",
    "\n",
    "def encode_verdict(verdict: str) -> int:\n",
    "    return 1 if verdict.strip().lower() == 'real' else 0\n",
    "\n",
    "def encode_confidence(conf: str) -> int:\n",
    "    mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "    return mapping.get(conf.strip().lower(), 1)  # 預設給信心程度1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4378c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # 觀察測試用!!!\n",
    "# sample_texts = data['text'].sample(10, random_state=42)\n",
    "\n",
    "# for i, text in enumerate(sample_texts):\n",
    "#     result = analyze_message_with_multi_llm(text)\n",
    "#     print(\"推論結果：\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-LLM\n",
    "llm_results = data['text'].progress_apply(analyze_message_with_multi_llm)\n",
    "llm_df = pd.DataFrame(llm_results.tolist())\n",
    "\n",
    "# encode\n",
    "llm_df['verdict_encoded'] = llm_df['verdict'].apply(encode_verdict)\n",
    "llm_df['confidence_encoded'] = llm_df['confidence'].apply(encode_confidence)\n",
    "\n",
    "X_final = pd.concat([X_final, llm_df[['verdict_encoded', 'confidence_encoded']]], axis=1)\n",
    "y_final = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# classifier models\n",
    "classifier_model = {\n",
    "    \"LogReg\"       : LogisticRegression(max_iter=1000),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"SVM\"          : SVC(kernel='linear', probability=True),\n",
    "    \"RandomForest\" : RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "# === init result ===\n",
    "results = []\n",
    "\n",
    "# === 建立 Stratified K-Fold ===\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# === 訓練每個模型 ===\n",
    "for name, model in classifier_model.items():\n",
    "    print(f\"\\n 訓練模型: {name}\")\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # 對所有特徵標準化\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    scores = cross_validate(pipeline, X_final, y, cv=cv, scoring=scoring)\n",
    "    result = {\n",
    "        'model': name,\n",
    "        'accuracy': np.mean(scores['test_accuracy']),\n",
    "        'f1': np.mean(scores['test_f1']),\n",
    "        'precision': np.mean(scores['test_precision']),\n",
    "        'recall': np.mean(scores['test_recall'])\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# === 整理成 DataFrame 顯示 ===\n",
    "result_df = pd.DataFrame(results)\n",
    "print(\"\\n各模型評估結果：\")\n",
    "print(result_df.sort_values(by='f1', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07b0a05b872c48ec8bc00ec063304866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bd81346eb5446ae86c8992ea87a8979": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3aa0234db1f4447da06ae0ba78593276",
       "IPY_MODEL_aaefd6793ed644b3afbf183bec859bff",
       "IPY_MODEL_e108b8551f0e41b69ce386e7cbdf3945"
      ],
      "layout": "IPY_MODEL_9c0fc22fc33a4388b5cde67492782329"
     }
    },
    "2ff3e28618eb412c9f1879564137be6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30cfa6df7235440a8aaf12b38e7c1a24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3aa0234db1f4447da06ae0ba78593276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7bd128141e746019bbd9eeed16eda0c",
      "placeholder": "​",
      "style": "IPY_MODEL_c9da9c06c90a475ab7e45abc95f3dec3",
      "value": "Batches: 100%"
     }
    },
    "953dd787d72045bc9382fef65869ced1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c0fc22fc33a4388b5cde67492782329": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7bd128141e746019bbd9eeed16eda0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaefd6793ed644b3afbf183bec859bff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_953dd787d72045bc9382fef65869ced1",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30cfa6df7235440a8aaf12b38e7c1a24",
      "value": 5
     }
    },
    "c9da9c06c90a475ab7e45abc95f3dec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e108b8551f0e41b69ce386e7cbdf3945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ff3e28618eb412c9f1879564137be6c",
      "placeholder": "​",
      "style": "IPY_MODEL_07b0a05b872c48ec8bc00ec063304866",
      "value": " 5/5 [00:09&lt;00:00,  1.28s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
