{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "399db7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama  # 使用 Ollama 封裝的 LLaMA 模型\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 定義輸出結構\n",
    "class MessageClassification(BaseModel):\n",
    "    verdict: str = Field(description=\"Verdict whether the message is Real or Fake\")\n",
    "    confidence: str = Field(description=\"Confidence level of the judgment (e.g., High, Medium, Low)\")\n",
    "    reason: str = Field(description=\"Brief explanation of the judgment\")\n",
    "\n",
    "# 使用本地 LLaMA 模型（例如 llama3）\n",
    "judge_llm = ChatOllama(model=\"llama3:8b\")\n",
    "logic_llm = ChatOllama(model=\"phi3\")\n",
    "debater_llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "# Json 輸出格式解析器\n",
    "parser = JsonOutputParser(pydantic_object=MessageClassification)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "# 單一 LLM 推理的 Prompt\n",
    "llm_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a professional fact-checker. Analyze the following message and determine if it is real or fake.\n",
    "\n",
    "Message:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\n",
    "Fill out the following JSON strictly without any additional text:\n",
    "\n",
    "{{\n",
    "  \"verdict\": \"\",        // \"Real\" or \"Fake\"\n",
    "  \"confidence\": \"\",     // \"High\", \"Medium\", or \"Low\"\n",
    "  \"reason\": \"\"          // Short explanation (1-2 sentences)\n",
    "}}\n",
    "\n",
    "Remember:\n",
    "- DO NOT add anything outside the JSON.\n",
    "- DO NOT wrap it in markdown (e.g., ```json).\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 讓 judge_llm 匯總所有模型觀點的 Prompt\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are the final arbiter. Three experts have evaluated the message. Please summarize their opinions and give your final decision.\n",
    "\n",
    "Message:\n",
    "\\\"\\\"\\\"{message}\\\"\\\"\\\"\n",
    "\n",
    "Expert 1 (Logic-focused model):\n",
    "{logic_opinion}\n",
    "\n",
    "Expert 2 (Debate-focused model):\n",
    "{debate_opinion}\n",
    "\n",
    "Expert 3 (Your own opinion):\n",
    "{your_opinion}\n",
    "\n",
    "Now summarize the opinions, resolve any conflicts, and provide a final classification in this JSON format:\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8344cdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verdict': 'Real', 'confidence': 'High', 'reason': 'The tweet appears to be from an authentic account as per the provided username, Donald J. Trump (@realDonaldTrump), and there is a timestamp that aligns with his known Twitter activity patterns.'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_json(text: str) -> dict:\n",
    "    # 找出第一組結構為 { ... } 的JSON區塊\n",
    "    match = re.search(r'{[\\s\\S]*?}', text)\n",
    "    if not match:\n",
    "        raise ValueError(\"No valid JSON object found in output.\")\n",
    "    json_str = match.group()\n",
    "    return json.loads(json_str)\n",
    "\n",
    "def call_llm(llm, prompt):\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content if hasattr(response, \"content\") else response\n",
    "\n",
    "# 定義分析函式\n",
    "def analyze_message_with_multi_llm(message: str):\n",
    "    logic_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "    debate_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "    judge_input = llm_prompt.format(message=message, format_instructions=format_instructions)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {\n",
    "            executor.submit(call_llm, logic_llm, logic_input): \"logic\",\n",
    "            executor.submit(call_llm, debater_llm, debate_input): \"debate\",\n",
    "            executor.submit(call_llm, judge_llm, judge_input): \"judge\"\n",
    "        }\n",
    "        results = {}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            key = futures[future]\n",
    "            results[key] = future.result()\n",
    "\n",
    "    summary_input = summary_prompt.format(\n",
    "        message=message,\n",
    "        logic_opinion=results[\"logic\"],\n",
    "        debate_opinion=results[\"debate\"],\n",
    "        your_opinion=results[\"judge\"],\n",
    "        format_instructions=format_instructions\n",
    "    )\n",
    "\n",
    "    final_response = judge_llm.invoke(summary_input)\n",
    "    result = extract_json(final_response.content)\n",
    "    return result\n",
    "\n",
    "# 測試訊息\n",
    "# 載入資料集\n",
    "fake_df = pd.read_csv('./raw_data/fake.csv')\n",
    "first_text = fake_df['text'].iloc[0]\n",
    "message = f\"Breaking: {first_text}\"\n",
    "result = analyze_message_with_multi_llm(message)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
